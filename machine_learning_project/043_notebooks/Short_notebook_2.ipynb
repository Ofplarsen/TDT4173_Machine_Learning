{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# TDT4173 Machine Learning Short Notebook 2\n",
    "\n",
    "### Kaggle username: Group 43\n",
    "\n",
    "### Blackboard group: 043\n",
    "\n",
    "#### Team members: Ola Sæther (544629), Olav Finne Præsteng Larsen (542616), Simeon Christoffersen (543897)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.660889600Z",
     "start_time": "2023-11-07T23:05:15.588873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CatBoost and AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Path Constants\n",
    "\n",
    "<strong> !NOTE! Change for your path during testing !NOTE! </strong>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_X_train_estimated_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_train_estimated\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_train_estimated.parquet'\n",
    "\n",
    "def get_X_train_observed_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_train_observed\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_train_observed.parquet'\n",
    "\n",
    "def get_target_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing target\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f\"../data/{dataset}/train_targets.parquet\"\n",
    "\n",
    "def get_test_estimated_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_test_estimated\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_test_estimated.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.683895Z",
     "start_time": "2023-11-07T23:05:15.604876600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_data(dataset):\n",
    "    \"\"\"\n",
    "    Method for combining the target datasets y, with the X_estimated and X_observed. Also adds a column for knowing what data is estimated and not. This column is called validation.\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_train_estimated = pd.read_parquet(get_X_train_estimated_path(dataset))\n",
    "    X_train_observed = pd.read_parquet(get_X_train_observed_path(dataset))\n",
    "    target = pd.read_parquet(get_target_path(dataset))\n",
    "\n",
    "    X_train_estimated['validation'] = True\n",
    "    X_train_observed['validation'] = False\n",
    "\n",
    "    df = pd.concat([X_train_observed, X_train_estimated], axis=0)\n",
    "    df.rename(columns={\"date_forecast\":\"datetime\"}, inplace=True)\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "    target['date'] = target['time'].dt.date\n",
    "    target['hour'] = target['time'].dt.hour\n",
    "    df = df.merge(target, on=['date','hour'], how='inner')\n",
    "\n",
    "    df = df.dropna(subset=['pv_measurement'])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['date_calc'], inplace=True)\n",
    "    df.drop(columns=['date', 'hour','time'], inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.695897800Z",
     "start_time": "2023-11-07T23:05:15.620880400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_features = ['precip_type_5min_idx', 'dew_or_rime_idx', 'is_day_idx', 'is_in_shadow_idx']\n",
    "X_test_A = pd.read_parquet(get_test_estimated_path('A'))\n",
    "X_test_A = X_test_A.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_A = X_test_A.drop(columns=['date_calc'])\n",
    "X_test_A.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_B = pd.read_parquet(get_test_estimated_path('B'))\n",
    "X_test_B = X_test_B.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_B = X_test_B.drop(columns=['date_calc'])\n",
    "X_test_B.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X_test_C = pd.read_parquet(get_test_estimated_path('C'))\n",
    "X_test_C = X_test_C.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_C = X_test_C.drop(columns=['date_calc'])\n",
    "X_test_C.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.908853700Z",
     "start_time": "2023-11-07T23:05:15.653887500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_A = combine_data('A')\n",
    "merged_B = combine_data('B')\n",
    "merged_C = combine_data('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Cleaning and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.922856100Z",
     "start_time": "2023-11-07T23:05:15.914855200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_frequent(x):\n",
    "    \"\"\"\n",
    "    Method used to combine rows from quarters into hours for categorical features. Takes the feature that is most present for that hour and sets is as the value for the hour\n",
    "    :param x: 4 values, 1 for each quarter of the hour\n",
    "    :return: The value that should be set for the hour\n",
    "    \"\"\"\n",
    "    counts = x.value_counts()\n",
    "    if counts.empty:\n",
    "        return None\n",
    "    return counts.index[0] if all(counts == counts.iloc[0]) else counts.idxmax()\n",
    "\n",
    "\n",
    "\n",
    "def remove_24h_zeros(df, column):\n",
    "    \"\"\"\n",
    "    Method to remove rolling consecutive zeros in the datasets. Includes the current row and counts number of zeros, if there are more than 24, it means the entire day is 0, then it continues until it find the next actual value, and removes those rows. They are considered \"bad data\".\n",
    "    :param df: Dataset\n",
    "    :param column: Pv_measurement column\n",
    "    :return: Dataset without consecutive zeros\n",
    "    \"\"\"\n",
    "    zeros_mask = df[column] == 0\n",
    "\n",
    "    # Use rolling sum to count consecutive zeros, shift the window by 23 periods\n",
    "    # because rolling() includes the current row by default\n",
    "    rolling_zeros = zeros_mask.rolling(window=24, min_periods=24).sum().shift(-23)\n",
    "\n",
    "    # Keep rows where the count of rolling sum of consecutive zeros is less than 24\n",
    "    df_filtered = df[rolling_zeros < 24]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "\n",
    "def feature_eng(df):\n",
    "    \"\"\"\n",
    "    Method for feature engineering each dataset.\n",
    "\n",
    "    Removes columns:['cloud_base_agl_m', 'ceiling_height_agl_m', 'snow_density_kgm3', 'snow_drift_idx', 'elevation_m']\n",
    "\n",
    "    Merges the dataset from each row being a quarter, to each row being an hour. This is done differently for the different features, where the features that measures something every quarter, like direct_rad_w are summed into an hour. Features like humidity are taken the mean of each quarter to represent the hour, and features that measures something for the last hour, like clear_sky_energy_1h_J, have the last quarter taken as the value for the hour, since they measure the last hour. Categorical features like percip_type, have the most frequent value added as hourly value.\n",
    "\n",
    "    :param df: Dataset\n",
    "    :return: Dataset that has merged rows, removed columns, and added columns based on sin/cos of hour, day, month\n",
    "    \"\"\"\n",
    "    df.drop(columns=['cloud_base_agl_m', 'ceiling_height_agl_m', 'snow_density_kgm3', 'snow_drift_idx', 'elevation_m'], inplace=True)\n",
    "\n",
    "    sum_cols = [ 'clear_sky_rad_W','direct_rad_W', 'diffuse_rad_W', 'precip_5min_mm', 'rain_water_kgm2', 'snow_water_kgm2', 'snow_melt_10min_mm', 'super_cooled_liquid_water_kgm2']\n",
    "    \n",
    "    last_cols = ['clear_sky_energy_1h_J','direct_rad_1h_J','fresh_snow_1h_cm', 'diffuse_rad_1h_J','fresh_snow_6h_cm', 'fresh_snow_3h_cm', 'fresh_snow_12h_cm', 'fresh_snow_24h_cm']\n",
    "    \n",
    "    \n",
    "    mean_columns = [col for col in df.columns if col not in categorical_features and col not in sum_cols and col not in last_cols]\n",
    "    agg_dict = {col: 'mean' for col in mean_columns}\n",
    "    agg_dict.update({col: most_frequent for col in categorical_features})\n",
    "    agg_dict.update({col: 'sum' for col in sum_cols})\n",
    "    agg_dict.update({col: 'last' for col in last_cols})\n",
    "\n",
    "    df = df.resample('H').agg(agg_dict)\n",
    "\n",
    "    df.sort_index(inplace=True)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df.index.hour / 24)\n",
    "    df['cos_month'] = np.cos(2 * np.pi * (df.index.month) / 12)\n",
    "    df['cos_day_of_month'] = np.cos(2*np.pi * df.index.day / 30 )\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df.index.hour / 24)\n",
    "    df['sin_day_of_month'] = np.sin(2*np.pi * df.index.day / 30 )\n",
    "    df['sin_month'] = np.sin(2 * np.pi * (df.index.month) / 12)\n",
    "    return df\n",
    "\n",
    "def clean_train(df):\n",
    "    \"\"\"\n",
    "    Method for cleaning the training data. Replaces : with _ in the colum names. Removes any days that have a daily sum of pv_measurement of 0, since no power was generated that day, which the group recognizes as bad data\n",
    "\n",
    "    :param df: Dataset\n",
    "    :return: Cleaned Dataset\n",
    "    \"\"\"\n",
    "    df.columns = [col.replace(':', '_') for col in df.columns]\n",
    "\n",
    "    df['DailySum'] = df.groupby(df.index.date)['pv_measurement'].transform('sum')\n",
    "    df = df[df['DailySum'] > 0]\n",
    "    df.drop('DailySum', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_test(df):\n",
    "    \"\"\"\n",
    "    Method for cleaning test data. Fixes naming as above\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df.columns = [col.replace(':', '_') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def remove_static_pv_measurements(df, column):\n",
    "    \"\"\"\n",
    "    Method for removing static pv_measurements. This was found during EDA and the group removes pv_measurement if it has the same value for more than 2 hours after each other, unless the value is 0, because of nighttime.\n",
    "\n",
    "    :param df: Dataset\n",
    "    :param column: Column to check for. Pv_measurement\n",
    "    :return: Cleaned Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Boolean mask to check if the current value is the same as the previous and the next\n",
    "    same_as_prev = (df[column].shift(1) == df[column]) & (df[column] > 0)\n",
    "    same_as_next = (df[column].shift(-1) == df[column]) & (df[column] > 0)\n",
    "    \n",
    "    # Create a mask where either condition is True\n",
    "    mask_to_drop = same_as_prev | same_as_next\n",
    "    \n",
    "    # Drop rows where the mask is True\n",
    "    df_dropped = df[~mask_to_drop]\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "def remove_pv_measurements(df):\n",
    "    \"\"\"\n",
    "    Remove pv_measurement if less than 0.1 and if sun_elevation is lower than -5 degrees\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # drop all rows where pv_measurement > 0.1 and sun_elevation_d < -7\n",
    "    df = df[~((df['pv_measurement'] > 0.1) & (df['sun_elevation_d'] < -5))]\n",
    "    return df\n",
    "\n",
    "def clean_data(df_train, df_test, cat = True):\n",
    "    \"\"\"\n",
    "    Main method for data cleaning. Contains all methods described above. Also sets validation and test boolean on dataset\n",
    "    :param cat: Whether catboost or autogluon is running\n",
    "    :param df_train:\n",
    "    :param df_test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df_train.index = pd.to_datetime(df_train.index)\n",
    "    df_train = clean_train(df_train)\n",
    "    df_train['test'] = False\n",
    "\n",
    "    df_test.index = pd.to_datetime(df_test.index)\n",
    "    df_test = clean_test(df_test)\n",
    "\n",
    "    df_test['test'] = True\n",
    "    df_test['validation'] = True\n",
    "\n",
    "    df_train = feature_eng(df_train)    \n",
    "    df_test = feature_eng(df_test)\n",
    "    \n",
    "    df_train = remove_static_pv_measurements(df_train, 'pv_measurement')\n",
    "    df_train = remove_24h_zeros(df_train, 'pv_measurement')\n",
    "    if cat:\n",
    "        df_train = remove_pv_measurements(df_train)\n",
    "\n",
    "    df = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "    train_df = df[df['test'] == False].drop(columns=['test'])\n",
    "    test_df = df[df['test'] == True].drop(columns=['test', 'pv_measurement'])\n",
    "\n",
    "    # Asserts the testset has the correct length for easier debugging, instead of finding out after all training\n",
    "    assert len(test_df) == 720\n",
    "    train_df[categorical_features] = train_df[categorical_features].astype(int)\n",
    "    test_df[categorical_features] = test_df[categorical_features].astype(int)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.141989400Z",
     "start_time": "2023-11-07T23:05:15.924857400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_A_train, cleaned_A_test = clean_data(merged_A, X_test_A)\n",
    "cleaned_B_train, cleaned_B_test = clean_data(merged_B, X_test_B)\n",
    "cleaned_C_train, cleaned_C_test = clean_data(merged_C, X_test_C)\n",
    "\n",
    "# Asserts implemented to assert that there are non nan values in the datasets\n",
    "assert not cleaned_A_train.isna().any().any()\n",
    "assert not cleaned_A_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_B_train.isna().any().any()\n",
    "assert not cleaned_B_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_C_train.isna().any().any()\n",
    "assert not cleaned_C_test.isna().any().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.157108Z",
     "start_time": "2023-11-07T23:05:51.142989900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_validation_data(X, seed):\n",
    "    \"\"\"\n",
    "    Method for getting training and validation data. The split is 0.1.\n",
    "    :param X: Training data\n",
    "    :param seed: Seed for determining split. Added for reproducibility\n",
    "    :return: X_train, X_validation\n",
    "    \"\"\"\n",
    "    return train_test_split(X, test_size=0.1, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.174551700Z",
     "start_time": "2023-11-07T23:05:51.157108Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_regressor():\n",
    "    \"\"\"\n",
    "    Method for getting the same regressor with the same hyperparameters for all training rounds\n",
    "    :return: CatBoostRegressor with correct hyperparameters\n",
    "    \"\"\"\n",
    "    return CatBoostRegressor(loss_function='MAE', verbose=500, n_estimators=19054, l2_leaf_reg=5, depth=6, random_state=42, early_stopping_rounds=100, learning_rate=0.029854477813327555)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T23:05:51.172551200Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 616.9866212\ttest: 624.5743384\tbest: 624.5743384 (0)\ttotal: 172ms\tremaining: 54m 44s\n",
      "500:\tlearn: 189.9363002\ttest: 190.9024445\tbest: 190.9024445 (500)\ttotal: 10.7s\tremaining: 6m 37s\n",
      "1000:\tlearn: 173.6603677\ttest: 177.8841417\tbest: 177.8812507 (999)\ttotal: 21.2s\tremaining: 6m 23s\n",
      "1500:\tlearn: 167.8491291\ttest: 174.2847148\tbest: 174.2847148 (1500)\ttotal: 31.7s\tremaining: 6m 11s\n",
      "2000:\tlearn: 162.7864280\ttest: 172.3517130\tbest: 172.3517130 (2000)\ttotal: 42.2s\tremaining: 5m 59s\n",
      "2500:\tlearn: 158.4476499\ttest: 170.4560616\tbest: 170.4427827 (2495)\ttotal: 52.6s\tremaining: 5m 48s\n",
      "3000:\tlearn: 155.0901949\ttest: 169.3996843\tbest: 169.3931822 (2997)\ttotal: 1m 3s\tremaining: 5m 37s\n",
      "3500:\tlearn: 152.0539049\ttest: 168.1165459\tbest: 168.1165459 (3500)\ttotal: 1m 13s\tremaining: 5m 25s\n",
      "4000:\tlearn: 150.1111104\ttest: 167.6706009\tbest: 167.6695614 (3999)\ttotal: 1m 23s\tremaining: 5m 14s\n",
      "4500:\tlearn: 148.0702632\ttest: 167.0083550\tbest: 167.0061857 (4498)\ttotal: 1m 33s\tremaining: 5m 3s\n",
      "5000:\tlearn: 145.9976450\ttest: 166.4400399\tbest: 166.4400399 (5000)\ttotal: 1m 44s\tremaining: 4m 52s\n",
      "5500:\tlearn: 144.3170723\ttest: 165.8040929\tbest: 165.8033123 (5497)\ttotal: 1m 54s\tremaining: 4m 41s\n",
      "6000:\tlearn: 142.6533150\ttest: 165.3565005\tbest: 165.3565005 (6000)\ttotal: 2m 4s\tremaining: 4m 30s\n",
      "6500:\tlearn: 140.9508672\ttest: 164.7867934\tbest: 164.7729130 (6492)\ttotal: 2m 14s\tremaining: 4m 20s\n",
      "7000:\tlearn: 139.4585481\ttest: 164.2935144\tbest: 164.2727684 (6945)\ttotal: 2m 25s\tremaining: 4m 9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 164.2727684\n",
      "bestIteration = 6945\n",
      "\n",
      "Shrink model to first 6946 iterations.\n",
      "0:\tlearn: 621.2418468\ttest: 608.5308572\tbest: 608.5308572 (0)\ttotal: 22.3ms\tremaining: 7m 5s\n",
      "500:\tlearn: 189.5872754\ttest: 194.4503223\tbest: 194.4503223 (500)\ttotal: 10.2s\tremaining: 6m 16s\n",
      "1000:\tlearn: 173.1939853\ttest: 182.5304770\tbest: 182.5304770 (999)\ttotal: 20.4s\tremaining: 6m 7s\n",
      "1500:\tlearn: 166.6730335\ttest: 178.3656456\tbest: 178.3656456 (1500)\ttotal: 30.6s\tremaining: 5m 58s\n",
      "2000:\tlearn: 161.8395013\ttest: 175.5987966\tbest: 175.5987966 (2000)\ttotal: 40.9s\tremaining: 5m 48s\n",
      "2500:\tlearn: 157.7608362\ttest: 173.8579535\tbest: 173.8579535 (2500)\ttotal: 51.1s\tremaining: 5m 37s\n",
      "3000:\tlearn: 154.4152152\ttest: 172.7371159\tbest: 172.7364170 (2996)\ttotal: 1m 1s\tremaining: 5m 27s\n",
      "3500:\tlearn: 152.2292308\ttest: 172.0206073\tbest: 172.0189739 (3496)\ttotal: 1m 11s\tremaining: 5m 17s\n",
      "4000:\tlearn: 149.7261846\ttest: 171.1823905\tbest: 171.0862758 (3981)\ttotal: 1m 21s\tremaining: 5m 6s\n",
      "4500:\tlearn: 147.4271437\ttest: 170.3710105\tbest: 170.3702255 (4472)\ttotal: 1m 31s\tremaining: 4m 56s\n",
      "5000:\tlearn: 145.2814156\ttest: 169.5993497\tbest: 169.5993497 (5000)\ttotal: 1m 42s\tremaining: 4m 46s\n",
      "5500:\tlearn: 143.1217526\ttest: 168.9220266\tbest: 168.9044138 (5440)\ttotal: 1m 52s\tremaining: 4m 36s\n",
      "6000:\tlearn: 141.0052152\ttest: 168.3781074\tbest: 168.3461354 (5977)\ttotal: 2m 2s\tremaining: 4m 26s\n",
      "6500:\tlearn: 139.3677116\ttest: 167.7736523\tbest: 167.7736523 (6500)\ttotal: 2m 12s\tremaining: 4m 16s\n",
      "7000:\tlearn: 137.7089025\ttest: 167.2945770\tbest: 167.2906630 (6986)\ttotal: 2m 22s\tremaining: 4m 5s\n",
      "7500:\tlearn: 136.1372625\ttest: 166.6925760\tbest: 166.6925760 (7500)\ttotal: 2m 33s\tremaining: 3m 55s\n",
      "8000:\tlearn: 134.4786292\ttest: 166.3408550\tbest: 166.3208569 (7930)\ttotal: 2m 43s\tremaining: 3m 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 166.068814\n",
      "bestIteration = 8256\n",
      "\n",
      "Shrink model to first 8257 iterations.\n",
      "0:\tlearn: 620.2724995\ttest: 595.8147396\tbest: 595.8147396 (0)\ttotal: 25.6ms\tremaining: 8m 7s\n",
      "500:\tlearn: 190.3324546\ttest: 185.5413007\tbest: 185.5413007 (500)\ttotal: 10.4s\tremaining: 6m 26s\n",
      "1000:\tlearn: 173.4955267\ttest: 175.0552987\tbest: 175.0552987 (1000)\ttotal: 20.9s\tremaining: 6m 17s\n",
      "1500:\tlearn: 167.7929161\ttest: 172.5465946\tbest: 172.5465946 (1500)\ttotal: 31.3s\tremaining: 6m 6s\n",
      "2000:\tlearn: 162.5094983\ttest: 170.3844554\tbest: 170.3810269 (1998)\ttotal: 41.8s\tremaining: 5m 55s\n",
      "2500:\tlearn: 159.2176714\ttest: 169.0576726\tbest: 169.0567271 (2497)\ttotal: 51.9s\tremaining: 5m 43s\n",
      "3000:\tlearn: 155.6599596\ttest: 167.9065057\tbest: 167.9065057 (3000)\ttotal: 1m 2s\tremaining: 5m 32s\n",
      "3500:\tlearn: 153.1034386\ttest: 167.1938885\tbest: 167.1938336 (3499)\ttotal: 1m 12s\tremaining: 5m 20s\n",
      "4000:\tlearn: 150.3033521\ttest: 166.3168067\tbest: 166.3168067 (4000)\ttotal: 1m 22s\tremaining: 5m 10s\n",
      "4500:\tlearn: 147.9336310\ttest: 165.6425014\tbest: 165.6424657 (4499)\ttotal: 1m 32s\tremaining: 5m\n",
      "5000:\tlearn: 145.6016059\ttest: 164.8878363\tbest: 164.8877979 (4999)\ttotal: 1m 43s\tremaining: 4m 50s\n",
      "5500:\tlearn: 143.4298357\ttest: 164.3105673\tbest: 164.3105673 (5500)\ttotal: 1m 54s\tremaining: 4m 42s\n",
      "6000:\tlearn: 141.8575586\ttest: 163.9209868\tbest: 163.9162419 (5967)\ttotal: 2m 6s\tremaining: 4m 35s\n",
      "6500:\tlearn: 140.3408805\ttest: 163.4445725\tbest: 163.4421556 (6498)\ttotal: 2m 17s\tremaining: 4m 25s\n",
      "7000:\tlearn: 139.0084150\ttest: 163.0776316\tbest: 163.0776316 (7000)\ttotal: 2m 29s\tremaining: 4m 17s\n",
      "7500:\tlearn: 137.7604145\ttest: 162.7283310\tbest: 162.7281516 (7499)\ttotal: 2m 40s\tremaining: 4m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 162.4199652\n",
      "bestIteration = 7891\n",
      "\n",
      "Shrink model to first 7892 iterations.\n",
      "0:\tlearn: 616.3151071\ttest: 632.0383579\tbest: 632.0383579 (0)\ttotal: 25.9ms\tremaining: 8m 12s\n",
      "500:\tlearn: 188.3851463\ttest: 197.6440629\tbest: 197.6440629 (500)\ttotal: 10.9s\tremaining: 6m 43s\n",
      "1000:\tlearn: 172.3262112\ttest: 186.4830672\tbest: 186.4830672 (1000)\ttotal: 21.7s\tremaining: 6m 32s\n",
      "1500:\tlearn: 165.8765736\ttest: 183.0965079\tbest: 183.0893189 (1488)\ttotal: 32.5s\tremaining: 6m 20s\n",
      "2000:\tlearn: 161.5885350\ttest: 181.4419947\tbest: 181.4419947 (2000)\ttotal: 43.3s\tremaining: 6m 8s\n",
      "2500:\tlearn: 157.9032280\ttest: 180.1943054\tbest: 180.1943054 (2500)\ttotal: 53.9s\tremaining: 5m 56s\n",
      "3000:\tlearn: 154.7125211\ttest: 179.1532462\tbest: 179.1532462 (3000)\ttotal: 1m 4s\tremaining: 5m 44s\n",
      "3500:\tlearn: 152.3904990\ttest: 178.1525528\tbest: 178.1507327 (3492)\ttotal: 1m 14s\tremaining: 5m 32s\n",
      "4000:\tlearn: 149.7140715\ttest: 177.0612455\tbest: 177.0584992 (3999)\ttotal: 1m 25s\tremaining: 5m 21s\n",
      "4500:\tlearn: 147.2655988\ttest: 176.2695291\tbest: 176.2695291 (4500)\ttotal: 1m 35s\tremaining: 5m 10s\n",
      "5000:\tlearn: 145.1873482\ttest: 175.7849800\tbest: 175.7818915 (4996)\ttotal: 1m 46s\tremaining: 4m 59s\n",
      "5500:\tlearn: 143.6272048\ttest: 175.1390295\tbest: 175.1376307 (5499)\ttotal: 1m 57s\tremaining: 4m 48s\n",
      "6000:\tlearn: 141.7830573\ttest: 174.4495371\tbest: 174.4495371 (6000)\ttotal: 2m 7s\tremaining: 4m 37s\n",
      "6500:\tlearn: 140.1426001\ttest: 174.0176456\tbest: 173.9859274 (6486)\ttotal: 2m 18s\tremaining: 4m 27s\n",
      "7000:\tlearn: 138.6424008\ttest: 173.6826341\tbest: 173.6768376 (6995)\ttotal: 2m 28s\tremaining: 4m 16s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 173.4154214\n",
      "bestIteration = 7282\n",
      "\n",
      "Shrink model to first 7283 iterations.\n",
      "0:\tlearn: 624.2316581\ttest: 582.9704809\tbest: 582.9704809 (0)\ttotal: 24ms\tremaining: 7m 37s\n",
      "500:\tlearn: 190.2264843\ttest: 177.2619285\tbest: 177.2619285 (500)\ttotal: 10.6s\tremaining: 6m 34s\n",
      "1000:\tlearn: 174.2030789\ttest: 168.2430362\tbest: 168.2430362 (1000)\ttotal: 21.3s\tremaining: 6m 23s\n",
      "1500:\tlearn: 169.0519920\ttest: 165.4615693\tbest: 165.4582147 (1495)\ttotal: 31.8s\tremaining: 6m 12s\n",
      "2000:\tlearn: 164.3144912\ttest: 163.2096358\tbest: 163.2096358 (2000)\ttotal: 42.3s\tremaining: 6m\n",
      "2500:\tlearn: 160.0513308\ttest: 161.7097408\tbest: 161.6984579 (2485)\ttotal: 52.9s\tremaining: 5m 50s\n",
      "3000:\tlearn: 156.7902648\ttest: 160.4714064\tbest: 160.4714064 (3000)\ttotal: 1m 3s\tremaining: 5m 40s\n",
      "3500:\tlearn: 153.5585921\ttest: 159.7376580\tbest: 159.7084471 (3446)\ttotal: 1m 14s\tremaining: 5m 29s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 159.7084471\n",
      "bestIteration = 3446\n",
      "\n",
      "Shrink model to first 3447 iterations.\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 54, 66, 358, 123456]\n",
    "preds_A = []\n",
    "for i in seeds:\n",
    "    X_A, Val_A = get_validation_data(cleaned_A_train, i)\n",
    "    model_a = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_A, label=X_A.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_A, label=Val_A.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    \n",
    "    X_pool_test = Pool(cleaned_A_test, cat_features=categorical_features)\n",
    "    \n",
    "    model_a.fit(X_pool,eval_set=[X_pool_val])\n",
    "\n",
    "    \n",
    "    prediction_A = model_a.predict(X_pool_test)\n",
    "    preds_A.append(prediction_A)\n",
    "    \n",
    "prediction_A = np.mean(preds_A, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 102.4837694\ttest: 101.7755848\tbest: 101.7755848 (0)\ttotal: 20.5ms\tremaining: 6m 31s\n",
      "500:\tlearn: 24.4087947\ttest: 26.2104956\tbest: 26.2104956 (500)\ttotal: 9.75s\tremaining: 6m 1s\n",
      "1000:\tlearn: 22.9604440\ttest: 25.3502606\tbest: 25.3493427 (988)\ttotal: 19.3s\tremaining: 5m 48s\n",
      "1500:\tlearn: 22.1840960\ttest: 25.0673780\tbest: 25.0661993 (1497)\ttotal: 28.9s\tremaining: 5m 38s\n",
      "2000:\tlearn: 21.5823521\ttest: 24.8790912\tbest: 24.8742428 (1986)\ttotal: 38.5s\tremaining: 5m 27s\n",
      "2500:\tlearn: 21.0739991\ttest: 24.6557092\tbest: 24.6530070 (2497)\ttotal: 48s\tremaining: 5m 17s\n",
      "3000:\tlearn: 20.5397941\ttest: 24.4975940\tbest: 24.4975940 (3000)\ttotal: 57.5s\tremaining: 5m 7s\n",
      "3500:\tlearn: 20.1174016\ttest: 24.3773786\tbest: 24.3764902 (3471)\ttotal: 1m 7s\tremaining: 5m\n",
      "4000:\tlearn: 19.7243861\ttest: 24.2468284\tbest: 24.2453412 (3993)\ttotal: 1m 17s\tremaining: 4m 50s\n",
      "4500:\tlearn: 19.3673498\ttest: 24.1616414\tbest: 24.1601585 (4495)\ttotal: 1m 26s\tremaining: 4m 40s\n",
      "5000:\tlearn: 19.0741022\ttest: 24.1073678\tbest: 24.0976392 (4952)\ttotal: 1m 36s\tremaining: 4m 30s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 24.09763924\n",
      "bestIteration = 4952\n",
      "\n",
      "Shrink model to first 4953 iterations.\n",
      "0:\tlearn: 101.7183531\ttest: 105.4293351\tbest: 105.4293351 (0)\ttotal: 21.5ms\tremaining: 6m 49s\n",
      "500:\tlearn: 24.3447613\ttest: 27.5885480\tbest: 27.5885480 (500)\ttotal: 9.97s\tremaining: 6m 9s\n",
      "1000:\tlearn: 22.8773340\ttest: 26.8212926\tbest: 26.8212926 (1000)\ttotal: 19.9s\tremaining: 5m 59s\n",
      "1500:\tlearn: 22.1542833\ttest: 26.4913765\tbest: 26.4890830 (1498)\ttotal: 29.7s\tremaining: 5m 47s\n",
      "2000:\tlearn: 21.5409956\ttest: 26.2265438\tbest: 26.2263846 (1995)\ttotal: 39.3s\tremaining: 5m 34s\n",
      "2500:\tlearn: 20.9486104\ttest: 26.0015317\tbest: 26.0015317 (2500)\ttotal: 48.8s\tremaining: 5m 22s\n",
      "3000:\tlearn: 20.5035283\ttest: 25.8637450\tbest: 25.8637450 (3000)\ttotal: 58.2s\tremaining: 5m 11s\n",
      "3500:\tlearn: 20.0839806\ttest: 25.6675525\tbest: 25.6675453 (3499)\ttotal: 1m 9s\tremaining: 5m 8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 25.5416632\n",
      "bestIteration = 3877\n",
      "\n",
      "Shrink model to first 3878 iterations.\n",
      "0:\tlearn: 102.2336450\ttest: 100.8269797\tbest: 100.8269797 (0)\ttotal: 39.7ms\tremaining: 12m 35s\n",
      "500:\tlearn: 24.3559574\ttest: 25.0036616\tbest: 25.0036616 (500)\ttotal: 11s\tremaining: 6m 47s\n",
      "1000:\tlearn: 22.9256607\ttest: 24.1705359\tbest: 24.1704595 (997)\ttotal: 20.8s\tremaining: 6m 15s\n",
      "1500:\tlearn: 22.2118246\ttest: 23.9080237\tbest: 23.9051469 (1482)\ttotal: 31.1s\tremaining: 6m 3s\n",
      "2000:\tlearn: 21.5609155\ttest: 23.6318421\tbest: 23.6311560 (1992)\ttotal: 40.8s\tremaining: 5m 47s\n",
      "2500:\tlearn: 21.0197765\ttest: 23.4230032\tbest: 23.4201779 (2482)\ttotal: 50.4s\tremaining: 5m 33s\n",
      "3000:\tlearn: 20.5503979\ttest: 23.2467438\tbest: 23.2467438 (3000)\ttotal: 1m\tremaining: 5m 21s\n",
      "3500:\tlearn: 20.1490937\ttest: 23.1424488\tbest: 23.1419647 (3480)\ttotal: 1m 9s\tremaining: 5m 9s\n",
      "4000:\tlearn: 19.7425107\ttest: 23.0678675\tbest: 23.0677445 (3998)\ttotal: 1m 19s\tremaining: 4m 57s\n",
      "4500:\tlearn: 19.3830979\ttest: 22.9682463\tbest: 22.9679009 (4492)\ttotal: 1m 28s\tremaining: 4m 46s\n",
      "5000:\tlearn: 19.1031160\ttest: 22.8787476\tbest: 22.8774777 (4964)\ttotal: 1m 38s\tremaining: 4m 35s\n",
      "5500:\tlearn: 18.8362725\ttest: 22.7833973\tbest: 22.7833685 (5497)\ttotal: 1m 47s\tremaining: 4m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.73299042\n",
      "bestIteration = 5883\n",
      "\n",
      "Shrink model to first 5884 iterations.\n",
      "0:\tlearn: 101.8569892\ttest: 104.2838472\tbest: 104.2838472 (0)\ttotal: 20ms\tremaining: 6m 20s\n",
      "500:\tlearn: 24.5923046\ttest: 27.7993994\tbest: 27.7993994 (500)\ttotal: 9.84s\tremaining: 6m 4s\n",
      "1000:\tlearn: 23.0987081\ttest: 26.9494882\tbest: 26.9494882 (1000)\ttotal: 19.5s\tremaining: 5m 52s\n",
      "1500:\tlearn: 22.2442349\ttest: 26.5081759\tbest: 26.5081759 (1500)\ttotal: 29.2s\tremaining: 5m 41s\n",
      "2000:\tlearn: 21.5855119\ttest: 26.2102643\tbest: 26.2097258 (1998)\ttotal: 38.8s\tremaining: 5m 31s\n",
      "2500:\tlearn: 21.0013010\ttest: 26.0359363\tbest: 26.0359363 (2500)\ttotal: 48.5s\tremaining: 5m 20s\n",
      "3000:\tlearn: 20.5251072\ttest: 25.8429519\tbest: 25.8429519 (3000)\ttotal: 58.1s\tremaining: 5m 10s\n",
      "3500:\tlearn: 20.1531256\ttest: 25.7439571\tbest: 25.7436586 (3489)\ttotal: 1m 7s\tremaining: 5m\n",
      "4000:\tlearn: 19.7657858\ttest: 25.5966682\tbest: 25.5912815 (3996)\ttotal: 1m 17s\tremaining: 4m 50s\n",
      "4500:\tlearn: 19.4372582\ttest: 25.4845239\tbest: 25.4825188 (4489)\ttotal: 1m 26s\tremaining: 4m 40s\n",
      "5000:\tlearn: 19.1793151\ttest: 25.4000506\tbest: 25.3999783 (4999)\ttotal: 1m 35s\tremaining: 4m 29s\n",
      "5500:\tlearn: 18.9125941\ttest: 25.3179796\tbest: 25.3165114 (5496)\ttotal: 1m 44s\tremaining: 4m 17s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 25.29637718\n",
      "bestIteration = 5642\n",
      "\n",
      "Shrink model to first 5643 iterations.\n",
      "0:\tlearn: 101.8226344\ttest: 104.7177049\tbest: 104.7177049 (0)\ttotal: 20.1ms\tremaining: 6m 22s\n",
      "500:\tlearn: 24.3411368\ttest: 25.4831454\tbest: 25.4831454 (500)\ttotal: 9.84s\tremaining: 6m 4s\n",
      "1000:\tlearn: 22.8508118\ttest: 24.7375643\tbest: 24.7368906 (999)\ttotal: 19.4s\tremaining: 5m 50s\n",
      "1500:\tlearn: 22.0620853\ttest: 24.3282117\tbest: 24.3282117 (1500)\ttotal: 29s\tremaining: 5m 39s\n",
      "2000:\tlearn: 21.4353800\ttest: 24.0883270\tbest: 24.0853441 (1999)\ttotal: 38.6s\tremaining: 5m 28s\n",
      "2500:\tlearn: 20.8819170\ttest: 23.8163091\tbest: 23.8163091 (2500)\ttotal: 48.2s\tremaining: 5m 18s\n",
      "3000:\tlearn: 20.3882245\ttest: 23.6230219\tbest: 23.6229309 (2999)\ttotal: 57.7s\tremaining: 5m 8s\n",
      "3500:\tlearn: 19.9556784\ttest: 23.4767572\tbest: 23.4755250 (3498)\ttotal: 1m 7s\tremaining: 4m 59s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 23.34437995\n",
      "bestIteration = 3895\n",
      "\n",
      "Shrink model to first 3896 iterations.\n"
     ]
    }
   ],
   "source": [
    "preds_B = []\n",
    "for i in seeds:\n",
    "    X_B, Val_B = get_validation_data(cleaned_B_train,i)\n",
    "    model_b = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_B, label=X_B.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_B, label=Val_B.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_test = Pool(cleaned_B_test,cat_features=categorical_features)\n",
    "    \n",
    "    model_b.fit(X_pool,eval_set=X_pool_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_B = model_b.predict(X_pool_test)\n",
    "    preds_B.append(prediction_B)\n",
    "    \n",
    "prediction_B = np.mean(preds_B, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 93.2805971\ttest: 90.8268406\tbest: 90.8268406 (0)\ttotal: 17.9ms\tremaining: 5m 40s\n",
      "500:\tlearn: 21.5595037\ttest: 22.6023289\tbest: 22.6023289 (500)\ttotal: 8.75s\tremaining: 5m 24s\n",
      "1000:\tlearn: 20.2206213\ttest: 21.9536612\tbest: 21.9536612 (999)\ttotal: 17.4s\tremaining: 5m 13s\n",
      "1500:\tlearn: 19.3013282\ttest: 21.5367529\tbest: 21.5367529 (1500)\ttotal: 26s\tremaining: 5m 3s\n",
      "2000:\tlearn: 18.5691417\ttest: 21.2809085\tbest: 21.2808937 (1996)\ttotal: 34.5s\tremaining: 4m 54s\n",
      "2500:\tlearn: 18.0810763\ttest: 21.1224701\tbest: 21.1175786 (2484)\ttotal: 43.1s\tremaining: 4m 45s\n",
      "3000:\tlearn: 17.6158475\ttest: 20.9922030\tbest: 20.9922030 (3000)\ttotal: 51.6s\tremaining: 4m 36s\n",
      "3500:\tlearn: 17.2353239\ttest: 20.9330698\tbest: 20.9308635 (3499)\ttotal: 1m\tremaining: 4m 27s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.89735612\n",
      "bestIteration = 3708\n",
      "\n",
      "Shrink model to first 3709 iterations.\n",
      "0:\tlearn: 93.1190987\ttest: 93.3112604\tbest: 93.3112604 (0)\ttotal: 18.4ms\tremaining: 5m 49s\n",
      "500:\tlearn: 21.5343127\ttest: 23.9114324\tbest: 23.9114324 (500)\ttotal: 8.67s\tremaining: 5m 21s\n",
      "1000:\tlearn: 20.2875695\ttest: 23.3060967\tbest: 23.3051587 (998)\ttotal: 17.1s\tremaining: 5m 7s\n",
      "1500:\tlearn: 19.2934496\ttest: 22.9604903\tbest: 22.9604903 (1500)\ttotal: 25.5s\tremaining: 4m 58s\n",
      "2000:\tlearn: 18.4761310\ttest: 22.7759213\tbest: 22.7631578 (1991)\ttotal: 33.9s\tremaining: 4m 49s\n",
      "2500:\tlearn: 17.8210328\ttest: 22.5801775\tbest: 22.5777361 (2496)\ttotal: 42.3s\tremaining: 4m 39s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.48847041\n",
      "bestIteration = 2802\n",
      "\n",
      "Shrink model to first 2803 iterations.\n",
      "0:\tlearn: 93.3986523\ttest: 91.1709063\tbest: 91.1709063 (0)\ttotal: 20.8ms\tremaining: 6m 37s\n",
      "500:\tlearn: 21.4967896\ttest: 23.6009287\tbest: 23.6009287 (500)\ttotal: 8.41s\tremaining: 5m 11s\n",
      "1000:\tlearn: 20.0940780\ttest: 23.0686026\tbest: 23.0676459 (996)\ttotal: 16.7s\tremaining: 5m 1s\n",
      "1500:\tlearn: 19.2493524\ttest: 22.7938309\tbest: 22.7938308 (1499)\ttotal: 25s\tremaining: 4m 51s\n",
      "2000:\tlearn: 18.5583597\ttest: 22.5518818\tbest: 22.5518818 (2000)\ttotal: 33.2s\tremaining: 4m 43s\n",
      "2500:\tlearn: 17.9883184\ttest: 22.3876152\tbest: 22.3876152 (2500)\ttotal: 41.5s\tremaining: 4m 34s\n",
      "3000:\tlearn: 17.5546375\ttest: 22.2608479\tbest: 22.2608479 (3000)\ttotal: 49.8s\tremaining: 4m 26s\n",
      "3500:\tlearn: 17.1531487\ttest: 22.1794231\tbest: 22.1794231 (3500)\ttotal: 58.2s\tremaining: 4m 18s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.08865388\n",
      "bestIteration = 3851\n",
      "\n",
      "Shrink model to first 3852 iterations.\n",
      "0:\tlearn: 93.6992043\ttest: 93.6011481\tbest: 93.6011481 (0)\ttotal: 17.5ms\tremaining: 5m 34s\n",
      "500:\tlearn: 21.5237638\ttest: 22.3348193\tbest: 22.3348193 (500)\ttotal: 8.69s\tremaining: 5m 21s\n",
      "1000:\tlearn: 20.2207164\ttest: 21.7073650\tbest: 21.7064469 (994)\ttotal: 17.3s\tremaining: 5m 11s\n",
      "1500:\tlearn: 19.4285929\ttest: 21.3773803\tbest: 21.3749874 (1494)\ttotal: 25.8s\tremaining: 5m 1s\n",
      "2000:\tlearn: 18.6033901\ttest: 21.0901507\tbest: 21.0898946 (1998)\ttotal: 34.3s\tremaining: 4m 52s\n",
      "2500:\tlearn: 18.0001403\ttest: 20.9189709\tbest: 20.9179042 (2497)\ttotal: 42.9s\tremaining: 4m 43s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.83272521\n",
      "bestIteration = 2884\n",
      "\n",
      "Shrink model to first 2885 iterations.\n",
      "0:\tlearn: 93.6836120\ttest: 93.8048705\tbest: 93.8048705 (0)\ttotal: 17.8ms\tremaining: 5m 39s\n",
      "500:\tlearn: 21.6838026\ttest: 22.6620653\tbest: 22.6620385 (498)\ttotal: 8.54s\tremaining: 5m 16s\n",
      "1000:\tlearn: 20.3860842\ttest: 22.1147050\tbest: 22.1147050 (1000)\ttotal: 16.9s\tremaining: 5m 4s\n",
      "1500:\tlearn: 19.4365712\ttest: 21.7711770\tbest: 21.7711770 (1500)\ttotal: 25.2s\tremaining: 4m 55s\n",
      "2000:\tlearn: 18.6383077\ttest: 21.4666084\tbest: 21.4666084 (2000)\ttotal: 33.6s\tremaining: 4m 46s\n",
      "2500:\tlearn: 18.0325449\ttest: 21.2650450\tbest: 21.2611437 (2489)\ttotal: 42s\tremaining: 4m 38s\n",
      "3000:\tlearn: 17.5008394\ttest: 21.1326753\tbest: 21.1317714 (2997)\ttotal: 50.4s\tremaining: 4m 29s\n",
      "3500:\tlearn: 17.0487450\ttest: 21.0214030\tbest: 21.0214030 (3500)\ttotal: 58.9s\tremaining: 4m 21s\n",
      "4000:\tlearn: 16.6696125\ttest: 20.9375380\tbest: 20.9349086 (3927)\ttotal: 1m 7s\tremaining: 4m 13s\n",
      "4500:\tlearn: 16.3058013\ttest: 20.8892123\tbest: 20.8892123 (4500)\ttotal: 1m 15s\tremaining: 4m 5s\n",
      "5000:\tlearn: 15.9424676\ttest: 20.7979759\tbest: 20.7977227 (4999)\ttotal: 1m 24s\tremaining: 3m 56s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.76692964\n",
      "bestIteration = 5139\n",
      "\n",
      "Shrink model to first 5140 iterations.\n"
     ]
    }
   ],
   "source": [
    "preds_C = []\n",
    "for i in seeds:\n",
    "    X_C, Val_C = get_validation_data(cleaned_C_train,i)\n",
    "    model_c = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_C, label=X_C.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_C, label=Val_C.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_test = Pool(cleaned_C_test, cat_features=categorical_features)\n",
    "    \n",
    "    model_c.fit(X_pool,eval_set=X_pool_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_C = model_c.predict(X_pool_test)\n",
    "    preds_C.append(prediction_C)\n",
    "    \n",
    "prediction_C = np.mean(preds_C, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "assert len(prediction_A) == 720 and len(prediction_B) == 720 and len(prediction_C) == 720\n",
    "from datetime import datetime\n",
    "\n",
    "t = []\n",
    "t.extend(prediction_A)\n",
    "t.extend(prediction_B)\n",
    "t.extend(prediction_C)\n",
    "\n",
    "\n",
    "t = [max(i,0) for i in t] # Remove any negative values\n",
    "\n",
    "df_cat = pd.DataFrame({'id': range(720 * 3), 'prediction': [0] * (720 * 3)})\n",
    "df_cat['prediction'] = t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "def auto_gl(train_data, test_data,validation_data, n=5):\n",
    "    validation_data = validation_data.copy()\n",
    "    predictor = TabularPredictor(label='pv_measurement',eval_metric='mae', problem_type='regression')\n",
    "\n",
    "\n",
    "    predictor.fit(train_data, presets=['best_quality'], time_limit=10800)\n",
    "    predictor.evaluate(validation_data, silent=False)\n",
    "    top_models = predictor.leaderboard(validation_data, silent=False)\n",
    "\n",
    "    top_models = top_models.head(n)  # Select the top 10 models\n",
    "    top_model_predictions = []\n",
    "    for model in top_models['model']:\n",
    "        model_predictions = predictor.predict(test_data, model=model)\n",
    "        top_model_predictions.append(model_predictions)\n",
    "\n",
    "    mean_prediction = np.mean(top_model_predictions, axis=0)\n",
    "    submit_pred = mean_prediction.tolist()\n",
    "    mae = predictor.predict(validation_data.drop(columns=['pv_measurement']))\n",
    "\n",
    "\n",
    "    return submit_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test_A = pd.read_parquet('../data/A/X_test_estimated.parquet')\n",
    "X_test_A = X_test_A.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_A = X_test_A.drop(columns=['date_calc'])\n",
    "X_test_A.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_B = pd.read_parquet('../data/B/X_test_estimated.parquet')\n",
    "X_test_B = X_test_B.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_B = X_test_B.drop(columns=['date_calc'])\n",
    "X_test_B.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X_test_C = pd.read_parquet('../data/C/X_test_estimated.parquet')\n",
    "X_test_C = X_test_C.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_C = X_test_C.drop(columns=['date_calc'])\n",
    "X_test_C.set_index(\"datetime\", inplace=True)\n",
    "merged_A = combine_data('A')\n",
    "merged_B = combine_data('B')\n",
    "merged_C = combine_data('C')\n",
    "\n",
    "cleaned_A_train, cleaned_A_test = clean_data(merged_A, X_test_A, cat=False)\n",
    "cleaned_A_train[categorical_features] = cleaned_A_train[categorical_features].astype(\"category\")\n",
    "cleaned_A_test[categorical_features] = cleaned_A_test[categorical_features].astype(\"category\")\n",
    "\n",
    "\n",
    "cleaned_B_train, cleaned_B_test = clean_data(merged_B, X_test_B, cat=False)\n",
    "cleaned_B_train[categorical_features] = cleaned_B_train[categorical_features].astype(\"category\")\n",
    "cleaned_B_test[categorical_features] = cleaned_B_test[categorical_features].astype(\"category\")\n",
    "\n",
    "cleaned_C_train, cleaned_C_test = clean_data(merged_C, X_test_C, cat=False)\n",
    "cleaned_C_train[categorical_features] = cleaned_C_train[categorical_features].astype(\"category\")\n",
    "cleaned_C_test[categorical_features] = cleaned_C_test[categorical_features].astype(\"category\")\n",
    "\n",
    "assert not cleaned_A_train.isna().any().any()\n",
    "assert not cleaned_A_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_B_train.isna().any().any()\n",
    "assert not cleaned_B_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_C_train.isna().any().any()\n",
    "assert not cleaned_C_test.isna().any().any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231110_184206\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231110_184206\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "Disk Space Avail:   31.39 GB / 999.39 GB (3.1%)\n",
      "Train Data Rows:    30604\n",
      "Train Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    23516.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.24 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['precip_type_5min_idx', 'dew_or_rime_idx', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['precip_type_5min_idx', 'dew_or_rime_idx']\n",
      "\t\t('float', [])     : 42 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['validation', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-237.6002\t = Validation score   (-mean_absolute_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t17.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-238.7632\t = Validation score   (-mean_absolute_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t17.56s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-146.7081\t = Validation score   (-mean_absolute_error)\n",
      "\t38.76s\t = Training   runtime\n",
      "\t61.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-162.5264\t = Validation score   (-mean_absolute_error)\n",
      "\t40.77s\t = Training   runtime\n",
      "\t57.45s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-180.8641\t = Validation score   (-mean_absolute_error)\n",
      "\t9.76s\t = Training   runtime\n",
      "\t0.91s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-168.7927\t = Validation score   (-mean_absolute_error)\n",
      "\t809.1s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-180.8313\t = Validation score   (-mean_absolute_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-182.2583\t = Validation score   (-mean_absolute_error)\n",
      "\t39.16s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-174.5064\t = Validation score   (-mean_absolute_error)\n",
      "\t95.1s\t = Training   runtime\n",
      "\t9.46s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-165.4567\t = Validation score   (-mean_absolute_error)\n",
      "\t154.19s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-158.3821\t = Validation score   (-mean_absolute_error)\n",
      "\t129.03s\t = Training   runtime\n",
      "\t98.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-144.945\t = Validation score   (-mean_absolute_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-148.713\t = Validation score   (-mean_absolute_error)\n",
      "\t5.42s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-144.3478\t = Validation score   (-mean_absolute_error)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-143.9639\t = Validation score   (-mean_absolute_error)\n",
      "\t17.02s\t = Training   runtime\n",
      "\t1.21s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.4567\t = Validation score   (-mean_absolute_error)\n",
      "\t37.58s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-143.6328\t = Validation score   (-mean_absolute_error)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t1.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-144.8236\t = Validation score   (-mean_absolute_error)\n",
      "\t39.81s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-144.1075\t = Validation score   (-mean_absolute_error)\n",
      "\t4.03s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-146.0113\t = Validation score   (-mean_absolute_error)\n",
      "\t99.37s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-145.6943\t = Validation score   (-mean_absolute_error)\n",
      "\t8.36s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-141.2655\t = Validation score   (-mean_absolute_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1653.92s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231110_184206\\\")\n",
      "Evaluation: mean_absolute_error on test data: -135.7539341545188\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -135.7539341545188,\n",
      "    \"root_mean_squared_error\": -321.4162149366336,\n",
      "    \"mean_squared_error\": -103308.38322419225,\n",
      "    \"r2\": 0.9273291230650492,\n",
      "    \"pearsonr\": 0.9629872116278345,\n",
      "    \"median_absolute_error\": -3.9333520507811954\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_test   score_val  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3 -135.753934 -141.265531       19.807871     267.925849  1523.939124                 0.004001                0.000000           0.281977            3       True         22\n",
      "1   NeuralNetFastAI_BAG_L2 -136.059168 -144.823581       18.558798     264.875533  1358.496550                 0.357015                0.495014          39.810341            2       True         18\n",
      "2   RandomForestMSE_BAG_L2 -136.913910 -143.963865       18.531797     265.593567  1335.702886                 0.330014                1.213048          17.016677            2       True         15\n",
      "3          LightGBM_BAG_L2 -137.131109 -144.347790       18.258786     264.512519  1322.198401                 0.057003                0.132000           3.512192            2       True         14\n",
      "4     ExtraTreesMSE_BAG_L2 -137.294712 -143.632829       18.536794     265.412758  1322.343402                 0.335012                1.032239           3.657192            2       True         17\n",
      "5     LightGBMLarge_BAG_L2 -137.462362 -145.694308       18.415792     264.643778  1327.045516                 0.214009                0.263259           8.359307            2       True         21\n",
      "6           XGBoost_BAG_L2 -138.450584 -144.107467       18.354788     264.565532  1322.713436                 0.153005                0.185013           4.027227            2       True         19\n",
      "7          CatBoost_BAG_L2 -138.953084 -145.456677       18.232785     264.430518  1356.267930                 0.031002                0.050000          37.581720            2       True         16\n",
      "8        LightGBMXT_BAG_L1 -139.010364 -146.708149        1.939110      61.802047    38.764671                 1.939110               61.802047          38.764671            1       True          3\n",
      "9      WeightedEnsemble_L2 -139.517701 -144.945003        8.824932     160.205824   322.344460                 0.003001                0.000999           0.362017            2       True         12\n",
      "10   NeuralNetTorch_BAG_L2 -139.696643 -146.011303       18.540819     264.818533  1418.051798                 0.339036                0.438015          99.365589            2       True         20\n",
      "11       LightGBMXT_BAG_L2 -140.631243 -148.712972       18.330787     264.685536  1324.102946                 0.129004                0.305018           5.416737            2       True         13\n",
      "12    LightGBMLarge_BAG_L1 -152.947864 -158.382139        6.586807      98.076749   129.027490                 6.586807               98.076749         129.027490            1       True         11\n",
      "13         LightGBM_BAG_L1 -153.403468 -162.526354        2.092129      57.448772    40.769922                 2.092129               57.448772          40.769922            1       True          4\n",
      "14         CatBoost_BAG_L1 -160.886239 -168.792740        0.114521       0.084007   809.104511                 0.114521                0.084007         809.104511            1       True          6\n",
      "15   NeuralNetTorch_BAG_L1 -161.720511 -165.456662        0.296014       0.326030   154.190282                 0.296014                0.326030         154.190282            1       True         10\n",
      "16          XGBoost_BAG_L1 -165.038390 -174.506359        2.202089       9.460462    95.097449                 2.202089                9.460462          95.097449            1       True          9\n",
      "17  NeuralNetFastAI_BAG_L1 -172.864474 -182.258286        0.392015       0.519031    39.163908                 0.392015                0.519031          39.163908            1       True          8\n",
      "18  RandomForestMSE_BAG_L1 -178.169360 -180.864077        0.313685       0.914668     9.759074                 0.313685                0.914668           9.759074            1       True          5\n",
      "19    ExtraTreesMSE_BAG_L1 -179.168954 -180.831340        0.332013       0.925534     2.741899                 0.332013                0.925534           2.741899            1       True          7\n",
      "20   KNeighborsUnif_BAG_L1 -234.830108 -237.600196        1.960081      17.263453     0.026000                 1.960081               17.263453           0.026000            1       True          1\n",
      "21   KNeighborsDist_BAG_L1 -235.388152 -238.763181        1.973321      17.559767     0.041003                 1.973321               17.559767           0.041003            1       True          2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_A, Val_A = get_validation_data(cleaned_A_train.copy(), seeds[0])\n",
    "cleaned_A_test_copy = cleaned_A_test.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prediction_A_auto = auto_gl(X_A, cleaned_A_test_copy, Val_A, n=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231110_191122\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231110_191122\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "Disk Space Avail:   28.82 GB / 999.39 GB (2.9%)\n",
      "Train Data Rows:    23740\n",
      "Train Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21422.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.84 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['precip_type_5min_idx', 'dew_or_rime_idx', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['precip_type_5min_idx', 'dew_or_rime_idx']\n",
      "\t\t('float', [])     : 42 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['validation', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.68 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-34.1874\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t10.86s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-34.2577\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t11.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8971\t = Validation score   (-mean_absolute_error)\n",
      "\t36.95s\t = Training   runtime\n",
      "\t43.89s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.9287\t = Validation score   (-mean_absolute_error)\n",
      "\t38.5s\t = Training   runtime\n",
      "\t33.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-25.9526\t = Validation score   (-mean_absolute_error)\n",
      "\t7.39s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.5528\t = Validation score   (-mean_absolute_error)\n",
      "\t755.22s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-25.6631\t = Validation score   (-mean_absolute_error)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-25.7628\t = Validation score   (-mean_absolute_error)\n",
      "\t32.24s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-24.3007\t = Validation score   (-mean_absolute_error)\n",
      "\t122.55s\t = Training   runtime\n",
      "\t51.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.2117\t = Validation score   (-mean_absolute_error)\n",
      "\t125.76s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.5779\t = Validation score   (-mean_absolute_error)\n",
      "\t118.5s\t = Training   runtime\n",
      "\t55.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-20.4818\t = Validation score   (-mean_absolute_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.5984\t = Validation score   (-mean_absolute_error)\n",
      "\t4.16s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.0669\t = Validation score   (-mean_absolute_error)\n",
      "\t3.05s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-20.5866\t = Validation score   (-mean_absolute_error)\n",
      "\t11.15s\t = Training   runtime\n",
      "\t0.83s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.1732\t = Validation score   (-mean_absolute_error)\n",
      "\t33.95s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-20.4483\t = Validation score   (-mean_absolute_error)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8916\t = Validation score   (-mean_absolute_error)\n",
      "\t29.98s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8207\t = Validation score   (-mean_absolute_error)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.2727\t = Validation score   (-mean_absolute_error)\n",
      "\t69.61s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.9245\t = Validation score   (-mean_absolute_error)\n",
      "\t8.26s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-20.2474\t = Validation score   (-mean_absolute_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1489.76s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231110_191122\\\")\n",
      "Evaluation: mean_absolute_error on test data: -20.837829601119118\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -20.837829601119118,\n",
      "    \"root_mean_squared_error\": -54.872347781168884,\n",
      "    \"mean_squared_error\": -3010.97455101755,\n",
      "    \"r2\": 0.933569210295462,\n",
      "    \"pearsonr\": 0.966247230026819,\n",
      "    \"median_absolute_error\": -0.32775768424391316\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_test  score_val  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_BAG_L2  -20.598364 -20.891609       16.700499     208.120447  1269.212930                 0.307007                0.384009          29.975584            2       True         18\n",
      "1      WeightedEnsemble_L3  -20.837830 -20.247386       17.904525     210.490481  1365.112838                 0.003000                0.000999           0.446010            3       True         22\n",
      "2     ExtraTreesMSE_BAG_L2  -20.888053 -20.448311       16.676497     208.549463  1241.719451                 0.283005                0.813025           2.482104            2       True         17\n",
      "3      WeightedEnsemble_L2  -21.078226 -20.481766        7.146753      99.471103   281.723789                 0.009001                0.000000           0.511012            2       True         12\n",
      "4     LightGBMLarge_BAG_L2  -21.120789 -20.924507       16.557495     207.981419  1247.501170                 0.164002                0.244981           8.263823            2       True         21\n",
      "5        LightGBMXT_BAG_L1  -21.128423 -20.897092        1.869579      43.889029    36.952650                 1.869579               43.889029          36.952650            1       True          3\n",
      "6   RandomForestMSE_BAG_L2  -21.203661 -20.586568       16.688499     208.569463  1250.389775                 0.295007                0.833025          11.152429            2       True         15\n",
      "7          LightGBM_BAG_L2  -21.210200 -21.066914       16.489495     207.839942  1242.289983                 0.096003                0.103504           3.052637            2       True         14\n",
      "8           XGBoost_BAG_L2  -21.290548 -20.820736       16.537496     207.875444  1243.183507                 0.144004                0.139006           3.946160            2       True         19\n",
      "9        LightGBMXT_BAG_L2  -21.615837 -21.598381       16.536496     207.971442  1243.399989                 0.143004                0.235004           4.162642            2       True         13\n",
      "10   NeuralNetTorch_BAG_L2  -21.688278 -21.272721       16.708500     208.075437  1308.846728                 0.315008                0.338999          69.609381            2       True         20\n",
      "11         CatBoost_BAG_L2  -21.728156 -21.173157       16.461495     207.788433  1273.183867                 0.068003                0.051995          33.946521            2       True         16\n",
      "12    LightGBMLarge_BAG_L1  -23.239899 -22.577862        5.041166      55.303550   118.499448                 5.041166               55.303550         118.499448            1       True         11\n",
      "13         LightGBM_BAG_L1  -23.391747 -22.928669        1.734040      33.018906    38.504344                 1.734040               33.018906          38.504344            1       True          4\n",
      "14   NeuralNetTorch_BAG_L1  -23.483092 -23.211671        0.227007       0.278524   125.760678                 0.227007                0.278524         125.760678            1       True         10\n",
      "15         CatBoost_BAG_L1  -24.428075 -23.552754        0.105014       0.087006   755.216658                 0.105014                0.087006         755.216658            1       True          6\n",
      "16          XGBoost_BAG_L1  -25.092292 -24.300661        4.192115      51.167202   122.546420                 4.192115               51.167202         122.546420            1       True          9\n",
      "17  NeuralNetFastAI_BAG_L1  -26.320383 -25.762805        0.290021       0.364013    32.239132                 0.290021                0.364013          32.239132            1       True          8\n",
      "18    ExtraTreesMSE_BAG_L1  -27.498791 -25.663134        0.279995       0.767602     2.086090                 0.279995                0.767602           2.086090            1       True          7\n",
      "19  RandomForestMSE_BAG_L1  -27.919413 -25.952627        0.292006       0.817031     7.385929                 0.292006                0.817031           7.385929            1       True          5\n",
      "20   KNeighborsUnif_BAG_L1  -36.570779 -34.187401        1.178374      10.858073     0.022997                 1.178374               10.858073           0.022997            1       True          1\n",
      "21   KNeighborsDist_BAG_L1  -36.731547 -34.257694        1.184175      11.185503     0.022999                 1.184175               11.185503           0.022999            1       True          2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_B, Val_B = get_validation_data(cleaned_B_train.copy(), seeds[0])\n",
    "cleaned_B_test_copy = cleaned_B_test.copy()\n",
    "\n",
    "prediction_B_auto = auto_gl(X_B, cleaned_B_test_copy, Val_B, n=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20231110_193743\\\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20231110_193743\\\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.10.2\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "Disk Space Avail:   25.31 GB / 999.39 GB (2.5%)\n",
      "Train Data Rows:    18166\n",
      "Train Data Columns: 47\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    21906.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.71 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['precip_type_5min_idx', 'dew_or_rime_idx', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t\t('float', [])    : 43 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['precip_type_5min_idx', 'dew_or_rime_idx']\n",
      "\t\t('float', [])     : 42 | ['absolute_humidity_2m_gm3', 'air_density_2m_kgm3', 'dew_point_2m_K', 'effective_cloud_cover_p', 'msl_pressure_hPa', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['validation', 'is_day_idx', 'is_in_shadow_idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t47 features in original data used to generate 47 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.58 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\t-29.3531\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t6.33s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\t-29.3932\t = Validation score   (-mean_absolute_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t6.3s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-18.914\t = Validation score   (-mean_absolute_error)\n",
      "\t28.58s\t = Training   runtime\n",
      "\t30.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.8121\t = Validation score   (-mean_absolute_error)\n",
      "\t30.39s\t = Training   runtime\n",
      "\t34.81s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-23.6749\t = Validation score   (-mean_absolute_error)\n",
      "\t4.92s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.082\t = Validation score   (-mean_absolute_error)\n",
      "\t686.86s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-23.1154\t = Validation score   (-mean_absolute_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.778\t = Validation score   (-mean_absolute_error)\n",
      "\t26.14s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.9937\t = Validation score   (-mean_absolute_error)\n",
      "\t85.54s\t = Training   runtime\n",
      "\t14.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.0892\t = Validation score   (-mean_absolute_error)\n",
      "\t114.85s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.7341\t = Validation score   (-mean_absolute_error)\n",
      "\t116.76s\t = Training   runtime\n",
      "\t50.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-18.6082\t = Validation score   (-mean_absolute_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.5594\t = Validation score   (-mean_absolute_error)\n",
      "\t4.85s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.2166\t = Validation score   (-mean_absolute_error)\n",
      "\t2.97s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-18.9975\t = Validation score   (-mean_absolute_error)\n",
      "\t7.95s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.3303\t = Validation score   (-mean_absolute_error)\n",
      "\t39.65s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-18.9146\t = Validation score   (-mean_absolute_error)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.0524\t = Validation score   (-mean_absolute_error)\n",
      "\t24.53s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.0764\t = Validation score   (-mean_absolute_error)\n",
      "\t4.2s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.5352\t = Validation score   (-mean_absolute_error)\n",
      "\t47.68s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.3277\t = Validation score   (-mean_absolute_error)\n",
      "\t8.8s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-18.6593\t = Validation score   (-mean_absolute_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1307.17s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20231110_193743\\\")\n",
      "Evaluation: mean_absolute_error on test data: -18.152373948516786\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"mean_absolute_error\": -18.152373948516786,\n",
      "    \"root_mean_squared_error\": -44.2317775866074,\n",
      "    \"mean_squared_error\": -1956.450148471105,\n",
      "    \"r2\": 0.9392831477190684,\n",
      "    \"pearsonr\": 0.9692266499314145,\n",
      "    \"median_absolute_error\": -0.9254559874534607\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     model  score_test  score_val  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   NeuralNetFastAI_BAG_L2  -17.971541 -19.052365       13.509895     144.848181  1120.046041                 0.248003                0.295008          24.529142            2       True         18\n",
      "1      WeightedEnsemble_L3  -17.984148 -18.659349       14.652917     146.819204  1193.766681                 0.010000                0.000000           0.469007            3       True         22\n",
      "2     ExtraTreesMSE_BAG_L2  -18.070235 -18.914575       13.467898     145.170184  1097.169929                 0.206005                0.617010           1.653030            2       True         17\n",
      "3   RandomForestMSE_BAG_L2  -18.131953 -18.997537       13.463895     145.170182  1103.471557                 0.202003                0.617008           7.954659            2       True         15\n",
      "4        LightGBMXT_BAG_L1  -18.142048 -18.913979        1.679029      30.783166    28.580690                 1.679029               30.783166          28.580690            1       True          3\n",
      "5      WeightedEnsemble_L2  -18.152374 -18.608155        2.125041      31.319185   170.066245                 0.003004                0.001001           0.501009            2       True         12\n",
      "6     LightGBMLarge_BAG_L2  -18.268162 -19.327652       13.463892     144.745167  1104.312740                 0.202000                0.191993           8.795842            2       True         21\n",
      "7           XGBoost_BAG_L2  -18.431720 -19.076410       13.404895     144.675185  1099.718527                 0.143003                0.122011           4.201628            2       True         19\n",
      "8          LightGBM_BAG_L2  -18.465967 -19.216591       13.305894     144.631175  1098.483952                 0.044002                0.078001           2.967053            2       True         14\n",
      "9        LightGBMXT_BAG_L2  -18.720714 -19.559376       13.354890     144.751179  1100.363019                 0.092998                0.198005           4.846121            2       True         13\n",
      "10   NeuralNetTorch_BAG_L2  -18.784447 -19.535216       13.597902     144.898172  1143.196321                 0.336009                0.344999          47.679423            2       True         20\n",
      "11         CatBoost_BAG_L2  -18.819234 -19.330285       13.290893     144.602177  1135.163402                 0.029001                0.049003          39.646503            2       True         16\n",
      "12    LightGBMLarge_BAG_L1  -19.754975 -20.734140        4.761111      50.218908   116.763450                 4.761111               50.218908         116.763450            1       True         11\n",
      "13         LightGBM_BAG_L1  -19.870916 -20.812135        1.667051      34.805947    30.392540                 1.667051               34.805947          30.392540            1       True          4\n",
      "14   NeuralNetTorch_BAG_L1  -20.439151 -21.089241        0.205005       0.242004   114.848603                 0.205005                0.242004         114.848603            1       True         10\n",
      "15         CatBoost_BAG_L1  -20.465141 -21.082020        0.102004       0.084012   686.861111                 0.102004                0.084012         686.861111            1       True          6\n",
      "16          XGBoost_BAG_L1  -20.649062 -21.993711        2.760048      14.334522    85.536379                 2.760048               14.334522          85.536379            1       True          9\n",
      "17  NeuralNetFastAI_BAG_L1  -21.670225 -22.778019        0.238004       0.293013    26.135943                 0.238004                0.293013          26.135943            1       True          8\n",
      "18    ExtraTreesMSE_BAG_L1  -22.694849 -23.115371        0.210004       0.590818     1.436034                 0.210004                0.590818           1.436034            1       True          7\n",
      "19  RandomForestMSE_BAG_L1  -22.949595 -23.674931        0.210003       0.567378     4.918150                 0.210003                0.567378           4.918150            1       True          5\n",
      "20   KNeighborsDist_BAG_L1  -28.357914 -29.393217        0.723108       6.301550     0.024001                 0.723108                6.301550           0.024001            1       True          2\n",
      "21   KNeighborsUnif_BAG_L1  -28.388256 -29.353140        0.706525       6.331855     0.019999                 0.706525                6.331855           0.019999            1       True          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_C, Val_C = get_validation_data(cleaned_C_train.copy(), seeds[0])\n",
    "cleaned_C_test_copy = cleaned_C_test.copy()\n",
    "\n",
    "prediction_C_auto = auto_gl(X_C, cleaned_C_test_copy, Val_C, n=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "assert len(prediction_A_auto) == 720 and len(prediction_B_auto) == 720 and len(prediction_C_auto) == 720\n",
    "from datetime import datetime\n",
    "\n",
    "t_auto = []\n",
    "t_auto.extend(prediction_A_auto)\n",
    "t_auto.extend(prediction_B_auto)\n",
    "t_auto.extend(prediction_C_auto)\n",
    "\n",
    "\n",
    "t_auto = [max(i,0) for i in t_auto] # Remove any negative values\n",
    "\n",
    "df_autogluon = pd.DataFrame({'id': range(720 * 3), 'prediction': [0] * (720 * 3)})\n",
    "df_autogluon['prediction'] = t_auto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Combine predictions to submit file\n",
    "We got the best results using a 90/10 split cat/autogluon, but think a 70/30 is more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "df['id'] = df_cat['id']\n",
    "df['prediction'] = (df_cat['prediction'] * 0.7 + df_autogluon['prediction']*0.3) * 0.4 + df_cat['prediction'] * 0.6\n",
    "\n",
    "df.to_csv(f'submission_{str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))}_notebook_2.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
