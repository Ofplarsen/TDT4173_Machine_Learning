{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# TDT4173 Machine Learning Short Notebook 1\n",
    "\n",
    "### Kaggle username: Group 43\n",
    "\n",
    "### Blackboard group: 043\n",
    "\n",
    "\n",
    "#### Team members: Ola Sæther (544629), Olav Finne Præsteng Larsen (542616), Simeon Christoffersen (543897)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.660889600Z",
     "start_time": "2023-11-07T23:05:15.588873Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CatBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Path Constants\n",
    "\n",
    "<strong> !NOTE! Change for your path during testing !NOTE! </strong>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def get_X_train_estimated_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_train_estimated\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_train_estimated.parquet'\n",
    "\n",
    "def get_X_train_observed_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_train_observed\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_train_observed.parquet'\n",
    "\n",
    "def get_target_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing target\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f\"../data/{dataset}/train_targets.parquet\"\n",
    "\n",
    "def get_test_estimated_path(dataset):\n",
    "    \"\"\"\n",
    "    Path for importing X_test_estimated\n",
    "    Change for what the path during testing is when reviewing\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return f'../data/{dataset}/X_test_estimated.parquet'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Grouping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def combine_data(dataset):\n",
    "    \"\"\"\n",
    "    Method for combining the target datasets y, with the X_estimated and X_observed. Also adds a column for knowing what data is estimated and not. This column is called validation.\n",
    "    :param dataset:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X_train_estimated = pd.read_parquet(get_X_train_estimated_path(dataset))\n",
    "    X_train_observed = pd.read_parquet(get_X_train_observed_path(dataset))\n",
    "    target = pd.read_parquet(get_target_path(dataset))\n",
    "\n",
    "\n",
    "    X_train_estimated['validation'] = True\n",
    "    X_train_observed['validation'] = False\n",
    "\n",
    "    df = pd.concat([X_train_observed, X_train_estimated], axis=0)\n",
    "    df.rename(columns={\"date_forecast\":\"datetime\"}, inplace=True)\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "    target['date'] = target['time'].dt.date\n",
    "    target['hour'] = target['time'].dt.hour\n",
    "    df = df.merge(target, on=['date','hour'], how='inner')\n",
    "\n",
    "    df = df.dropna(subset=['pv_measurement'])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.drop(columns=['date_calc'], inplace=True)\n",
    "    df.drop(columns=['date', 'hour','time'], inplace=True)\n",
    "\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.683895Z",
     "start_time": "2023-11-07T23:05:15.604876600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "categorical_features = ['precip_type_5min_idx', 'dew_or_rime_idx', 'is_day_idx', 'is_in_shadow_idx']\n",
    "X_test_A = pd.read_parquet(get_test_estimated_path('A'))\n",
    "X_test_A = X_test_A.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_A = X_test_A.drop(columns=['date_calc'])\n",
    "X_test_A.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_test_B = pd.read_parquet(get_test_estimated_path('B'))\n",
    "X_test_B = X_test_B.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_B = X_test_B.drop(columns=['date_calc'])\n",
    "X_test_B.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X_test_C = pd.read_parquet(get_test_estimated_path('C'))\n",
    "X_test_C = X_test_C.rename(columns={'date_forecast': 'datetime'})\n",
    "X_test_C = X_test_C.drop(columns=['date_calc'])\n",
    "X_test_C.set_index(\"datetime\", inplace=True)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.695897800Z",
     "start_time": "2023-11-07T23:05:15.620880400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "merged_A = combine_data('A')\n",
    "merged_B = combine_data('B')\n",
    "merged_C = combine_data('C')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.908853700Z",
     "start_time": "2023-11-07T23:05:15.653887500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning and feature engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def most_frequent(x):\n",
    "    \"\"\"\n",
    "    Method used to combine rows from quarters into hours for categorical features. Takes the feature that is most present for that hour and sets is as the value for the hour\n",
    "    :param x: 4 values, 1 for each quarter of the hour\n",
    "    :return: The value that should be set for the hour\n",
    "    \"\"\"\n",
    "    counts = x.value_counts()\n",
    "    if counts.empty:\n",
    "        return None\n",
    "    return counts.index[0] if all(counts == counts.iloc[0]) else counts.idxmax()\n",
    "\n",
    "\n",
    "\n",
    "def remove_24h_zeros(df, column):\n",
    "    \"\"\"\n",
    "    Method to remove rolling consecutive zeros in the datasets. Includes the current row and counts number of zeros, if there are more than 24, it means the entire day is 0, then it continues until it find the next actual value, and removes those rows. They are considered \"bad data\".\n",
    "    :param df: Dataset\n",
    "    :param column: Pv_measurement column\n",
    "    :return: Dataset without consecutive zeros\n",
    "    \"\"\"\n",
    "    zeros_mask = df[column] == 0\n",
    "\n",
    "    # Use rolling sum to count consecutive zeros, shift the window by 23 periods\n",
    "    # because rolling() includes the current row by default\n",
    "    rolling_zeros = zeros_mask.rolling(window=24, min_periods=24).sum().shift(-23)\n",
    "\n",
    "    # Keep rows where the count of rolling sum of consecutive zeros is less than 24\n",
    "    df_filtered = df[rolling_zeros < 24]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "\n",
    "def feature_eng(df):\n",
    "    \"\"\"\n",
    "    Method for feature engineering each dataset.\n",
    "\n",
    "    Removes columns:['cloud_base_agl_m', 'ceiling_height_agl_m', 'snow_density_kgm3', 'snow_drift_idx', 'elevation_m']\n",
    "\n",
    "    Merges the dataset from each row being a quarter, to each row being an hour. This is done differently for the different features, where the features that measures something every quarter, like direct_rad_w are summed into an hour. Features like humidity are taken the mean of each quarter to represent the hour, and features that measures something for the last hour, like clear_sky_energy_1h_J, have the last quarter taken as the value for the hour, since they measure the last hour. Categorical features like percip_type, have the most frequent value added as hourly value.\n",
    "\n",
    "    :param df: Dataset\n",
    "    :return: Dataset that has merged rows, removed columns, and added columns based on sin/cos of hour, day, month\n",
    "    \"\"\"\n",
    "\n",
    "    df.drop(columns=['cloud_base_agl_m', 'ceiling_height_agl_m', 'snow_density_kgm3', 'snow_drift_idx', 'elevation_m'], inplace=True)\n",
    "        #Sum\n",
    "    sum_cols = [ 'clear_sky_rad_W','direct_rad_W', 'diffuse_rad_W', 'precip_5min_mm', 'rain_water_kgm2', 'snow_water_kgm2', 'snow_melt_10min_mm', 'super_cooled_liquid_water_kgm2']\n",
    "    \n",
    "    # Last\n",
    "    last_cols = ['clear_sky_energy_1h_J','direct_rad_1h_J','fresh_snow_1h_cm', 'diffuse_rad_1h_J','fresh_snow_6h_cm', 'fresh_snow_3h_cm', 'fresh_snow_12h_cm', 'fresh_snow_24h_cm']\n",
    "    \n",
    "    \n",
    "    mean_columns = [col for col in df.columns if col not in categorical_features and col not in sum_cols and col not in last_cols]\n",
    "    agg_dict = {col: 'mean' for col in mean_columns}\n",
    "    agg_dict.update({col: most_frequent for col in categorical_features})\n",
    "    agg_dict.update({col: 'sum' for col in sum_cols})\n",
    "    agg_dict.update({col: 'last' for col in last_cols})\n",
    "\n",
    "    df = df.resample('H').agg(agg_dict)\n",
    "\n",
    "    df.sort_index(inplace=True)\n",
    "    df['cos_hour'] = np.cos(2 * np.pi * df.index.hour / 24)\n",
    "    df['cos_month'] = np.cos(2 * np.pi * (df.index.month) / 12)\n",
    "    df['cos_day_of_month'] = np.cos(2*np.pi * df.index.day / 30 )\n",
    "    df['sin_hour'] = np.sin(2 * np.pi * df.index.hour / 24)\n",
    "    df['sin_day_of_month'] = np.sin(2*np.pi * df.index.day / 30 )\n",
    "    df['sin_month'] = np.sin(2 * np.pi * (df.index.month) / 12)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_train(df):\n",
    "    \"\"\"\n",
    "    Method for cleaning the training data. Replaces : with _ in the colum names. Removes any days that have a daily sum of pv_measurement of 0, since no power was generated that day, which the group recognizes as bad data\n",
    "\n",
    "    :param df: Dataset\n",
    "    :return: Cleaned Dataset\n",
    "    \"\"\"\n",
    "    df.columns = [col.replace(':', '_') for col in df.columns]\n",
    "\n",
    "    df['DailySum'] = df.groupby(df.index.date)['pv_measurement'].transform('sum')\n",
    "    df = df[df['DailySum'] > 0]\n",
    "    df.drop('DailySum', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_test(df):\n",
    "    \"\"\"\n",
    "    Method for cleaning test data. Fixes naming as above\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df.columns = [col.replace(':', '_') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def remove_static_pv_measurements(df, column):\n",
    "    \"\"\"\n",
    "    Method for removing static pv_measurements. This was found during EDA and the group removes pv_measurement if it has the same value for more than 2 hours after each other, unless the value is 0, because of nighttime.\n",
    "\n",
    "    :param df: Dataset\n",
    "    :param column: Column to check for. Pv_measurement\n",
    "    :return: Cleaned Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    # Boolean mask to check if the current value is the same as the previous and the next\n",
    "    same_as_prev = (df[column].shift(1) == df[column]) & (df[column] > 0)\n",
    "    same_as_next = (df[column].shift(-1) == df[column]) & (df[column] > 0)\n",
    "    \n",
    "    # Create a mask where either condition is True\n",
    "    mask_to_drop = same_as_prev | same_as_next\n",
    "    \n",
    "    # Drop rows where the mask is True\n",
    "    df_dropped = df[~mask_to_drop]\n",
    "\n",
    "    return df_dropped\n",
    "\n",
    "def remove_pv_measurements(df):\n",
    "    \"\"\"\n",
    "    Remove pv_measurement if less than 0.1 and if sun_elevation is lower than -5 degrees\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # drop all rows where pv_measurement > 0.1 and sun_elevation_d < -7\n",
    "    df = df[~((df['pv_measurement'] > 0.1) & (df['sun_elevation_d'] < -5))]\n",
    "    return df\n",
    "\n",
    "def clean_data(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Main method for data cleaning. Contains all methods described above. Also sets validation and test boolean on dataset\n",
    "    :param df_train:\n",
    "    :param df_test:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    df_train.index = pd.to_datetime(df_train.index)\n",
    "    df_train = clean_train(df_train)\n",
    "    df_train['test'] = False\n",
    "\n",
    "    df_test.index = pd.to_datetime(df_test.index)\n",
    "    df_test = clean_test(df_test)\n",
    "\n",
    "    df_test['test'] = True\n",
    "    df_test['validation'] = True\n",
    "\n",
    "    df_train = feature_eng(df_train)    \n",
    "    df_test = feature_eng(df_test)\n",
    "    \n",
    "    df_train = remove_static_pv_measurements(df_train, 'pv_measurement')\n",
    "    df_train = remove_24h_zeros(df_train, 'pv_measurement')\n",
    "    df_train = remove_pv_measurements(df_train)\n",
    "\n",
    "    df = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    train_df = df[df['test'] == False].drop(columns=['test'])\n",
    "    test_df = df[df['test'] == True].drop(columns=['test', 'pv_measurement'])\n",
    "\n",
    "    # Asserts the testset has the correct length for easier debugging, instead of finding out after all training\n",
    "    assert len(test_df) == 720\n",
    "    train_df[categorical_features] = train_df[categorical_features].astype(int)\n",
    "    test_df[categorical_features] = test_df[categorical_features].astype(int)\n",
    "    \n",
    "    return train_df, test_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:15.922856100Z",
     "start_time": "2023-11-07T23:05:15.914855200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "cleaned_A_train, cleaned_A_test = clean_data(merged_A, X_test_A)\n",
    "cleaned_B_train, cleaned_B_test = clean_data(merged_B, X_test_B)\n",
    "cleaned_C_train, cleaned_C_test = clean_data(merged_C, X_test_C)\n",
    "\n",
    "# Asserts implemented to assert that there are non nan values in the datasets\n",
    "assert not cleaned_A_train.isna().any().any()\n",
    "assert not cleaned_A_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_B_train.isna().any().any()\n",
    "assert not cleaned_B_test.isna().any().any()\n",
    "\n",
    "assert not cleaned_C_train.isna().any().any()\n",
    "assert not cleaned_C_test.isna().any().any()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.141989400Z",
     "start_time": "2023-11-07T23:05:15.924857400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_validation_data(X, seed):\n",
    "    \"\"\"\n",
    "    Method for getting training and validation data. The split is 0.1.\n",
    "    :param X: Training data\n",
    "    :param seed: Seed for determining split. Added for reproducibility\n",
    "    :return: X_train, X_validation\n",
    "    \"\"\"\n",
    "    return train_test_split(X, test_size=0.1, random_state=seed)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.157108Z",
     "start_time": "2023-11-07T23:05:51.142989900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def get_regressor():\n",
    "    \"\"\"\n",
    "    Method for getting the same regressor with the same hyperparameters for all training rounds\n",
    "    :return: CatBoostRegressor with correct hyperparameters\n",
    "    \"\"\"\n",
    "    return CatBoostRegressor(loss_function='MAE', verbose=500, n_estimators=19054, l2_leaf_reg=5, depth=6, random_state=42, early_stopping_rounds=100, learning_rate=0.029854477813327555)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T23:05:51.174551700Z",
     "start_time": "2023-11-07T23:05:51.157108Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 616.9866212\ttest: 624.5743384\tbest: 624.5743384 (0)\ttotal: 24.8ms\tremaining: 8m 14s\n",
      "500:\tlearn: 189.9363002\ttest: 190.9024445\tbest: 190.9024445 (500)\ttotal: 12.4s\tremaining: 8m 2s\n",
      "1000:\tlearn: 173.6603677\ttest: 177.8841417\tbest: 177.8812507 (999)\ttotal: 24.1s\tremaining: 7m 37s\n",
      "1500:\tlearn: 167.8491291\ttest: 174.2847148\tbest: 174.2847148 (1500)\ttotal: 35.8s\tremaining: 7m 21s\n",
      "2000:\tlearn: 162.7864280\ttest: 172.3517130\tbest: 172.3517130 (2000)\ttotal: 48.5s\tremaining: 7m 15s\n",
      "2500:\tlearn: 158.4476499\ttest: 170.4560616\tbest: 170.4427827 (2495)\ttotal: 1m\tremaining: 6m 59s\n",
      "3000:\tlearn: 155.0901949\ttest: 169.3996843\tbest: 169.3931822 (2997)\ttotal: 1m 13s\tremaining: 6m 53s\n",
      "3500:\tlearn: 152.0539049\ttest: 168.1165459\tbest: 168.1165459 (3500)\ttotal: 1m 24s\tremaining: 6m 36s\n",
      "4000:\tlearn: 150.1111104\ttest: 167.6706009\tbest: 167.6695614 (3999)\ttotal: 1m 37s\tremaining: 6m 28s\n",
      "4500:\tlearn: 148.0702632\ttest: 167.0083550\tbest: 167.0061857 (4498)\ttotal: 1m 48s\tremaining: 6m 14s\n",
      "5000:\tlearn: 145.9976450\ttest: 166.4400399\tbest: 166.4400399 (5000)\ttotal: 2m\tremaining: 6m 1s\n",
      "5500:\tlearn: 144.3170723\ttest: 165.8040929\tbest: 165.8033123 (5497)\ttotal: 2m 12s\tremaining: 5m 48s\n",
      "6000:\tlearn: 142.6533150\ttest: 165.3565005\tbest: 165.3565005 (6000)\ttotal: 2m 24s\tremaining: 5m 36s\n",
      "6500:\tlearn: 140.9508672\ttest: 164.7867934\tbest: 164.7729130 (6492)\ttotal: 2m 36s\tremaining: 5m 23s\n",
      "7000:\tlearn: 139.4585481\ttest: 164.2935144\tbest: 164.2727684 (6945)\ttotal: 2m 48s\tremaining: 5m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 164.2727684\n",
      "bestIteration = 6945\n",
      "\n",
      "Shrink model to first 6946 iterations.\n",
      "0:\tlearn: 621.2418468\ttest: 608.5308572\tbest: 608.5308572 (0)\ttotal: 25.4ms\tremaining: 8m 27s\n",
      "500:\tlearn: 189.5872754\ttest: 194.4503223\tbest: 194.4503223 (500)\ttotal: 11.8s\tremaining: 7m 39s\n",
      "1000:\tlearn: 173.1939853\ttest: 182.5304770\tbest: 182.5304770 (999)\ttotal: 23.8s\tremaining: 7m 32s\n",
      "1500:\tlearn: 166.6730335\ttest: 178.3656456\tbest: 178.3656456 (1500)\ttotal: 36s\tremaining: 7m 23s\n",
      "2000:\tlearn: 161.8395013\ttest: 175.5987966\tbest: 175.5987966 (2000)\ttotal: 49s\tremaining: 7m 20s\n",
      "2500:\tlearn: 157.7608362\ttest: 173.8579535\tbest: 173.8579535 (2500)\ttotal: 1m 1s\tremaining: 7m 10s\n",
      "3000:\tlearn: 154.4152152\ttest: 172.7371159\tbest: 172.7364170 (2996)\ttotal: 1m 13s\tremaining: 6m 57s\n",
      "3500:\tlearn: 152.2292308\ttest: 172.0206073\tbest: 172.0189739 (3496)\ttotal: 1m 25s\tremaining: 6m 44s\n",
      "4000:\tlearn: 149.7261846\ttest: 171.1823905\tbest: 171.0862758 (3981)\ttotal: 1m 37s\tremaining: 6m 28s\n",
      "4500:\tlearn: 147.4271437\ttest: 170.3710105\tbest: 170.3702255 (4472)\ttotal: 1m 49s\tremaining: 6m 15s\n",
      "5000:\tlearn: 145.2814156\ttest: 169.5993497\tbest: 169.5993497 (5000)\ttotal: 2m\tremaining: 6m 1s\n",
      "5500:\tlearn: 143.1217526\ttest: 168.9220266\tbest: 168.9044138 (5440)\ttotal: 2m 12s\tremaining: 5m 48s\n",
      "6000:\tlearn: 141.0052152\ttest: 168.3781074\tbest: 168.3461354 (5977)\ttotal: 2m 23s\tremaining: 5m 35s\n",
      "6500:\tlearn: 139.3677116\ttest: 167.7736523\tbest: 167.7736523 (6500)\ttotal: 2m 34s\tremaining: 5m 20s\n",
      "7000:\tlearn: 137.7089025\ttest: 167.2945770\tbest: 167.2906630 (6986)\ttotal: 2m 44s\tremaining: 5m 5s\n",
      "7500:\tlearn: 136.1372625\ttest: 166.6925760\tbest: 166.6925760 (7500)\ttotal: 2m 55s\tremaining: 4m 52s\n",
      "8000:\tlearn: 134.4786292\ttest: 166.3408550\tbest: 166.3208569 (7930)\ttotal: 3m 8s\tremaining: 4m 41s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 166.068814\n",
      "bestIteration = 8256\n",
      "\n",
      "Shrink model to first 8257 iterations.\n",
      "0:\tlearn: 620.2724995\ttest: 595.8147396\tbest: 595.8147396 (0)\ttotal: 24ms\tremaining: 7m 58s\n",
      "500:\tlearn: 190.3324546\ttest: 185.5413007\tbest: 185.5413007 (500)\ttotal: 12s\tremaining: 7m 48s\n",
      "1000:\tlearn: 173.4955267\ttest: 175.0552987\tbest: 175.0552987 (1000)\ttotal: 24.2s\tremaining: 7m 39s\n",
      "1500:\tlearn: 167.7929161\ttest: 172.5465946\tbest: 172.5465946 (1500)\ttotal: 35.7s\tremaining: 7m 19s\n",
      "2000:\tlearn: 162.5094983\ttest: 170.3844554\tbest: 170.3810269 (1998)\ttotal: 46.6s\tremaining: 6m 58s\n",
      "2500:\tlearn: 159.2176714\ttest: 169.0576726\tbest: 169.0567271 (2497)\ttotal: 57.3s\tremaining: 6m 40s\n",
      "3000:\tlearn: 155.6599596\ttest: 167.9065057\tbest: 167.9065057 (3000)\ttotal: 1m 7s\tremaining: 6m 24s\n",
      "3500:\tlearn: 153.1034386\ttest: 167.1938885\tbest: 167.1938336 (3499)\ttotal: 1m 19s\tremaining: 6m 12s\n",
      "4000:\tlearn: 150.3033521\ttest: 166.3168067\tbest: 166.3168067 (4000)\ttotal: 1m 31s\tremaining: 6m 7s\n",
      "4500:\tlearn: 147.9336310\ttest: 165.6425014\tbest: 165.6424657 (4499)\ttotal: 1m 44s\tremaining: 6m\n",
      "5000:\tlearn: 145.6016059\ttest: 164.8878363\tbest: 164.8877979 (4999)\ttotal: 1m 57s\tremaining: 5m 50s\n",
      "5500:\tlearn: 143.4298357\ttest: 164.3105673\tbest: 164.3105673 (5500)\ttotal: 2m 8s\tremaining: 5m 38s\n",
      "6000:\tlearn: 141.8575586\ttest: 163.9209868\tbest: 163.9162419 (5967)\ttotal: 2m 21s\tremaining: 5m 29s\n",
      "6500:\tlearn: 140.3408805\ttest: 163.4445725\tbest: 163.4421556 (6498)\ttotal: 2m 33s\tremaining: 5m 17s\n",
      "7000:\tlearn: 139.0084150\ttest: 163.0776316\tbest: 163.0776316 (7000)\ttotal: 2m 44s\tremaining: 5m 5s\n",
      "7500:\tlearn: 137.7604145\ttest: 162.7283310\tbest: 162.7281516 (7499)\ttotal: 2m 55s\tremaining: 4m 52s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 162.4199652\n",
      "bestIteration = 7891\n",
      "\n",
      "Shrink model to first 7892 iterations.\n",
      "0:\tlearn: 616.3151071\ttest: 632.0383579\tbest: 632.0383579 (0)\ttotal: 26.2ms\tremaining: 8m 42s\n",
      "500:\tlearn: 188.3851463\ttest: 197.6440629\tbest: 197.6440629 (500)\ttotal: 11.6s\tremaining: 7m 32s\n",
      "1000:\tlearn: 172.3262112\ttest: 186.4830672\tbest: 186.4830672 (1000)\ttotal: 24s\tremaining: 7m 35s\n",
      "1500:\tlearn: 165.8765736\ttest: 183.0965079\tbest: 183.0893189 (1488)\ttotal: 38.6s\tremaining: 7m 55s\n",
      "2000:\tlearn: 161.5885350\ttest: 181.4419947\tbest: 181.4419947 (2000)\ttotal: 51.3s\tremaining: 7m 41s\n",
      "2500:\tlearn: 157.9032280\ttest: 180.1943054\tbest: 180.1943054 (2500)\ttotal: 1m 6s\tremaining: 7m 45s\n",
      "3000:\tlearn: 154.7125211\ttest: 179.1532462\tbest: 179.1532462 (3000)\ttotal: 1m 18s\tremaining: 7m 26s\n",
      "3500:\tlearn: 152.3904990\ttest: 178.1525528\tbest: 178.1507327 (3492)\ttotal: 1m 31s\tremaining: 7m 9s\n",
      "4000:\tlearn: 149.7140715\ttest: 177.0612455\tbest: 177.0584992 (3999)\ttotal: 1m 43s\tremaining: 6m 53s\n",
      "4500:\tlearn: 147.2655988\ttest: 176.2695291\tbest: 176.2695291 (4500)\ttotal: 1m 56s\tremaining: 6m 40s\n",
      "5000:\tlearn: 145.1873482\ttest: 175.7849800\tbest: 175.7818915 (4996)\ttotal: 2m 8s\tremaining: 6m 25s\n",
      "5500:\tlearn: 143.6272048\ttest: 175.1390295\tbest: 175.1376307 (5499)\ttotal: 2m 20s\tremaining: 6m 10s\n",
      "6000:\tlearn: 141.7830573\ttest: 174.4495371\tbest: 174.4495371 (6000)\ttotal: 2m 33s\tremaining: 5m 56s\n",
      "6500:\tlearn: 140.1426001\ttest: 174.0176456\tbest: 173.9859274 (6486)\ttotal: 2m 44s\tremaining: 5m 41s\n",
      "7000:\tlearn: 138.6424008\ttest: 173.6826341\tbest: 173.6768376 (6995)\ttotal: 2m 56s\tremaining: 5m 28s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 173.4154214\n",
      "bestIteration = 7282\n",
      "\n",
      "Shrink model to first 7283 iterations.\n",
      "0:\tlearn: 624.2316581\ttest: 582.9704809\tbest: 582.9704809 (0)\ttotal: 27.8ms\tremaining: 9m 14s\n",
      "500:\tlearn: 190.2264843\ttest: 177.2619285\tbest: 177.2619285 (500)\ttotal: 12.7s\tremaining: 8m 14s\n",
      "1000:\tlearn: 174.2030789\ttest: 168.2430362\tbest: 168.2430362 (1000)\ttotal: 25.6s\tremaining: 8m 6s\n",
      "1500:\tlearn: 169.0519920\ttest: 165.4615693\tbest: 165.4582147 (1495)\ttotal: 40.9s\tremaining: 8m 24s\n",
      "2000:\tlearn: 164.3144912\ttest: 163.2096358\tbest: 163.2096358 (2000)\ttotal: 53.3s\tremaining: 7m 58s\n",
      "2500:\tlearn: 160.0513308\ttest: 161.7097408\tbest: 161.6984579 (2485)\ttotal: 1m 5s\tremaining: 7m 37s\n",
      "3000:\tlearn: 156.7902648\ttest: 160.4714064\tbest: 160.4714064 (3000)\ttotal: 1m 17s\tremaining: 7m 19s\n",
      "3500:\tlearn: 153.5585921\ttest: 159.7376580\tbest: 159.7084471 (3446)\ttotal: 1m 30s\tremaining: 7m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 159.7084471\n",
      "bestIteration = 3446\n",
      "\n",
      "Shrink model to first 3447 iterations.\n"
     ]
    }
   ],
   "source": [
    "seeds = [42, 54, 66, 358, 123456]\n",
    "preds_A = []\n",
    "for i in seeds:\n",
    "    X_A, Val_A = get_validation_data(cleaned_A_train, i)\n",
    "    model_a = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_A, label=X_A.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_A, label=Val_A.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    \n",
    "    X_pool_test = Pool(cleaned_A_test, cat_features=categorical_features)\n",
    "    \n",
    "    model_a.fit(X_pool,eval_set=[X_pool_val])\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_A = model_a.predict(X_pool_test)\n",
    "    preds_A.append(prediction_A)\n",
    "    \n",
    "prediction_A = np.mean(preds_A, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-07T23:05:51.172551200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 102.4837694\ttest: 101.7755848\tbest: 101.7755848 (0)\ttotal: 22.1ms\tremaining: 7m 22s\n",
      "500:\tlearn: 24.4087947\ttest: 26.2104956\tbest: 26.2104956 (500)\ttotal: 10.9s\tremaining: 7m 2s\n",
      "1000:\tlearn: 22.9604440\ttest: 25.3502606\tbest: 25.3493427 (988)\ttotal: 21.4s\tremaining: 6m 45s\n",
      "1500:\tlearn: 22.1840960\ttest: 25.0673780\tbest: 25.0661993 (1497)\ttotal: 32s\tremaining: 6m 33s\n",
      "2000:\tlearn: 21.5823521\ttest: 24.8790912\tbest: 24.8742428 (1986)\ttotal: 42.5s\tremaining: 6m 21s\n",
      "2500:\tlearn: 21.0739991\ttest: 24.6557092\tbest: 24.6530070 (2497)\ttotal: 52.9s\tremaining: 6m 9s\n",
      "3000:\tlearn: 20.5397941\ttest: 24.4975940\tbest: 24.4975940 (3000)\ttotal: 1m 3s\tremaining: 6m\n",
      "3500:\tlearn: 20.1174016\ttest: 24.3773786\tbest: 24.3764902 (3471)\ttotal: 1m 14s\tremaining: 5m 49s\n",
      "4000:\tlearn: 19.7243861\ttest: 24.2468284\tbest: 24.2453412 (3993)\ttotal: 1m 24s\tremaining: 5m 39s\n",
      "4500:\tlearn: 19.3673498\ttest: 24.1616414\tbest: 24.1601585 (4495)\ttotal: 1m 36s\tremaining: 5m 30s\n",
      "5000:\tlearn: 19.0741022\ttest: 24.1073678\tbest: 24.0976392 (4952)\ttotal: 1m 47s\tremaining: 5m 20s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 24.09763924\n",
      "bestIteration = 4952\n",
      "\n",
      "Shrink model to first 4953 iterations.\n",
      "0:\tlearn: 101.7183531\ttest: 105.4293351\tbest: 105.4293351 (0)\ttotal: 25ms\tremaining: 8m 18s\n",
      "500:\tlearn: 24.3447613\ttest: 27.5885480\tbest: 27.5885480 (500)\ttotal: 11.4s\tremaining: 7m 23s\n",
      "1000:\tlearn: 22.8773340\ttest: 26.8212926\tbest: 26.8212926 (1000)\ttotal: 22.2s\tremaining: 7m\n",
      "1500:\tlearn: 22.1542833\ttest: 26.4913765\tbest: 26.4890830 (1498)\ttotal: 36.7s\tremaining: 7m 31s\n",
      "2000:\tlearn: 21.5409956\ttest: 26.2265438\tbest: 26.2263846 (1995)\ttotal: 50.2s\tremaining: 7m 30s\n",
      "2500:\tlearn: 20.9486104\ttest: 26.0015317\tbest: 26.0015317 (2500)\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "3000:\tlearn: 20.5035283\ttest: 25.8637450\tbest: 25.8637450 (3000)\ttotal: 1m 13s\tremaining: 6m 55s\n",
      "3500:\tlearn: 20.0839806\ttest: 25.6675525\tbest: 25.6675453 (3499)\ttotal: 1m 25s\tremaining: 6m 42s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 25.5416632\n",
      "bestIteration = 3877\n",
      "\n",
      "Shrink model to first 3878 iterations.\n",
      "0:\tlearn: 102.2336450\ttest: 100.8269797\tbest: 100.8269797 (0)\ttotal: 23ms\tremaining: 7m 40s\n",
      "500:\tlearn: 24.3559574\ttest: 25.0036616\tbest: 25.0036616 (500)\ttotal: 11.2s\tremaining: 7m 14s\n",
      "1000:\tlearn: 22.9256607\ttest: 24.1705359\tbest: 24.1704595 (997)\ttotal: 22.8s\tremaining: 7m 11s\n",
      "1500:\tlearn: 22.2118246\ttest: 23.9080237\tbest: 23.9051469 (1482)\ttotal: 35s\tremaining: 7m 10s\n",
      "2000:\tlearn: 21.5609155\ttest: 23.6318421\tbest: 23.6311560 (1992)\ttotal: 46.7s\tremaining: 6m 59s\n",
      "2500:\tlearn: 21.0197765\ttest: 23.4230032\tbest: 23.4201779 (2482)\ttotal: 57.6s\tremaining: 6m 42s\n",
      "3000:\tlearn: 20.5503979\ttest: 23.2467438\tbest: 23.2467438 (3000)\ttotal: 1m 10s\tremaining: 6m 37s\n",
      "3500:\tlearn: 20.1490937\ttest: 23.1424488\tbest: 23.1419647 (3480)\ttotal: 1m 22s\tremaining: 6m 27s\n",
      "4000:\tlearn: 19.7425107\ttest: 23.0678675\tbest: 23.0677445 (3998)\ttotal: 1m 33s\tremaining: 6m 14s\n",
      "4500:\tlearn: 19.3830979\ttest: 22.9682463\tbest: 22.9679009 (4492)\ttotal: 1m 45s\tremaining: 6m 2s\n",
      "5000:\tlearn: 19.1031160\ttest: 22.8787476\tbest: 22.8774777 (4964)\ttotal: 1m 56s\tremaining: 5m 48s\n",
      "5500:\tlearn: 18.8362725\ttest: 22.7833973\tbest: 22.7833685 (5497)\ttotal: 2m 6s\tremaining: 5m 33s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.73299042\n",
      "bestIteration = 5883\n",
      "\n",
      "Shrink model to first 5884 iterations.\n",
      "0:\tlearn: 101.8569892\ttest: 104.2838472\tbest: 104.2838472 (0)\ttotal: 23.6ms\tremaining: 7m 50s\n",
      "500:\tlearn: 24.5923046\ttest: 27.7993994\tbest: 27.7993994 (500)\ttotal: 12.8s\tremaining: 8m 19s\n",
      "1000:\tlearn: 23.0987081\ttest: 26.9494882\tbest: 26.9494882 (1000)\ttotal: 24.3s\tremaining: 7m 40s\n",
      "1500:\tlearn: 22.2442349\ttest: 26.5081759\tbest: 26.5081759 (1500)\ttotal: 36.2s\tremaining: 7m 25s\n",
      "2000:\tlearn: 21.5855119\ttest: 26.2102643\tbest: 26.2097258 (1998)\ttotal: 48.3s\tremaining: 7m 13s\n",
      "2500:\tlearn: 21.0013010\ttest: 26.0359363\tbest: 26.0359363 (2500)\ttotal: 1m 2s\tremaining: 7m 15s\n",
      "3000:\tlearn: 20.5251072\ttest: 25.8429519\tbest: 25.8429519 (3000)\ttotal: 1m 15s\tremaining: 7m 6s\n",
      "3500:\tlearn: 20.1531256\ttest: 25.7439571\tbest: 25.7436586 (3489)\ttotal: 1m 28s\tremaining: 6m 56s\n",
      "4000:\tlearn: 19.7657858\ttest: 25.5966682\tbest: 25.5912815 (3996)\ttotal: 1m 39s\tremaining: 6m 36s\n",
      "4500:\tlearn: 19.4372582\ttest: 25.4845239\tbest: 25.4825188 (4489)\ttotal: 1m 50s\tremaining: 6m 19s\n",
      "5000:\tlearn: 19.1793151\ttest: 25.4000506\tbest: 25.3999783 (4999)\ttotal: 2m 1s\tremaining: 6m 2s\n",
      "5500:\tlearn: 18.9125941\ttest: 25.3179796\tbest: 25.3165114 (5496)\ttotal: 2m 11s\tremaining: 5m 46s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 25.29637718\n",
      "bestIteration = 5642\n",
      "\n",
      "Shrink model to first 5643 iterations.\n",
      "0:\tlearn: 101.8226344\ttest: 104.7177049\tbest: 104.7177049 (0)\ttotal: 24.1ms\tremaining: 8m\n",
      "500:\tlearn: 24.3411368\ttest: 25.4831454\tbest: 25.4831454 (500)\ttotal: 10.7s\tremaining: 6m 54s\n",
      "1000:\tlearn: 22.8508118\ttest: 24.7375643\tbest: 24.7368906 (999)\ttotal: 21.2s\tremaining: 6m 41s\n",
      "1500:\tlearn: 22.0620853\ttest: 24.3282117\tbest: 24.3282117 (1500)\ttotal: 31.7s\tremaining: 6m 30s\n",
      "2000:\tlearn: 21.4353800\ttest: 24.0883270\tbest: 24.0853441 (1999)\ttotal: 42.3s\tremaining: 6m 20s\n",
      "2500:\tlearn: 20.8819170\ttest: 23.8163091\tbest: 23.8163091 (2500)\ttotal: 52.5s\tremaining: 6m 6s\n",
      "3000:\tlearn: 20.3882245\ttest: 23.6230219\tbest: 23.6229309 (2999)\ttotal: 1m 2s\tremaining: 5m 55s\n",
      "3500:\tlearn: 19.9556784\ttest: 23.4767572\tbest: 23.4755250 (3498)\ttotal: 1m 13s\tremaining: 5m 45s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 23.34437995\n",
      "bestIteration = 3895\n",
      "\n",
      "Shrink model to first 3896 iterations.\n"
     ]
    }
   ],
   "source": [
    "preds_B = []\n",
    "for i in seeds:\n",
    "    X_B, Val_B = get_validation_data(cleaned_B_train,i)\n",
    "    model_b = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_B, label=X_B.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_B, label=Val_B.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_test = Pool(cleaned_B_test,cat_features=categorical_features)\n",
    "    \n",
    "    model_b.fit(X_pool,eval_set=X_pool_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_B = model_b.predict(X_pool_test)\n",
    "    preds_B.append(prediction_B)\n",
    "    \n",
    "prediction_B = np.mean(preds_B, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 93.2805971\ttest: 90.8268406\tbest: 90.8268406 (0)\ttotal: 25.3ms\tremaining: 8m 26s\n",
      "500:\tlearn: 21.5595037\ttest: 22.6023289\tbest: 22.6023289 (500)\ttotal: 12.1s\tremaining: 7m 48s\n",
      "1000:\tlearn: 20.2206213\ttest: 21.9536612\tbest: 21.9536612 (999)\ttotal: 22.4s\tremaining: 7m 4s\n",
      "1500:\tlearn: 19.3013282\ttest: 21.5367529\tbest: 21.5367529 (1500)\ttotal: 33.2s\tremaining: 6m 48s\n",
      "2000:\tlearn: 18.5691417\ttest: 21.2809085\tbest: 21.2808937 (1996)\ttotal: 43.6s\tremaining: 6m 31s\n",
      "2500:\tlearn: 18.0810763\ttest: 21.1224701\tbest: 21.1175786 (2484)\ttotal: 54.9s\tremaining: 6m 24s\n",
      "3000:\tlearn: 17.6158475\ttest: 20.9922030\tbest: 20.9922030 (3000)\ttotal: 1m 5s\tremaining: 6m 12s\n",
      "3500:\tlearn: 17.2353239\ttest: 20.9330698\tbest: 20.9308635 (3499)\ttotal: 1m 16s\tremaining: 5m 59s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.89735612\n",
      "bestIteration = 3708\n",
      "\n",
      "Shrink model to first 3709 iterations.\n",
      "0:\tlearn: 93.1190987\ttest: 93.3112604\tbest: 93.3112604 (0)\ttotal: 20.1ms\tremaining: 6m 40s\n",
      "500:\tlearn: 21.5343127\ttest: 23.9114324\tbest: 23.9114324 (500)\ttotal: 9.97s\tremaining: 6m 27s\n",
      "1000:\tlearn: 20.2875695\ttest: 23.3060967\tbest: 23.3051587 (998)\ttotal: 21s\tremaining: 6m 37s\n",
      "1500:\tlearn: 19.2934496\ttest: 22.9604903\tbest: 22.9604903 (1500)\ttotal: 30.9s\tremaining: 6m 21s\n",
      "2000:\tlearn: 18.4761310\ttest: 22.7759213\tbest: 22.7631578 (1991)\ttotal: 41.9s\tremaining: 6m 16s\n",
      "2500:\tlearn: 17.8210328\ttest: 22.5801775\tbest: 22.5777361 (2496)\ttotal: 54.1s\tremaining: 6m 17s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.48847041\n",
      "bestIteration = 2802\n",
      "\n",
      "Shrink model to first 2803 iterations.\n",
      "0:\tlearn: 93.3986523\ttest: 91.1709063\tbest: 91.1709063 (0)\ttotal: 20.6ms\tremaining: 6m 52s\n",
      "500:\tlearn: 21.4967896\ttest: 23.6009287\tbest: 23.6009287 (500)\ttotal: 11.8s\tremaining: 7m 39s\n",
      "1000:\tlearn: 20.0940780\ttest: 23.0686026\tbest: 23.0676459 (996)\ttotal: 23.7s\tremaining: 7m 28s\n",
      "1500:\tlearn: 19.2493524\ttest: 22.7938309\tbest: 22.7938308 (1499)\ttotal: 34.4s\tremaining: 7m 3s\n",
      "2000:\tlearn: 18.5583597\ttest: 22.5518818\tbest: 22.5518818 (2000)\ttotal: 44.5s\tremaining: 6m 40s\n",
      "2500:\tlearn: 17.9883184\ttest: 22.3876152\tbest: 22.3876152 (2500)\ttotal: 55.2s\tremaining: 6m 25s\n",
      "3000:\tlearn: 17.5546375\ttest: 22.2608479\tbest: 22.2608479 (3000)\ttotal: 1m 5s\tremaining: 6m 9s\n",
      "3500:\tlearn: 17.1531487\ttest: 22.1794231\tbest: 22.1794231 (3500)\ttotal: 1m 15s\tremaining: 5m 54s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22.08865388\n",
      "bestIteration = 3851\n",
      "\n",
      "Shrink model to first 3852 iterations.\n",
      "0:\tlearn: 93.6992043\ttest: 93.6011481\tbest: 93.6011481 (0)\ttotal: 21.2ms\tremaining: 7m 4s\n",
      "500:\tlearn: 21.5237638\ttest: 22.3348193\tbest: 22.3348193 (500)\ttotal: 11.7s\tremaining: 7m 33s\n",
      "1000:\tlearn: 20.2207164\ttest: 21.7073650\tbest: 21.7064469 (994)\ttotal: 23.6s\tremaining: 7m 26s\n",
      "1500:\tlearn: 19.4285929\ttest: 21.3773803\tbest: 21.3749874 (1494)\ttotal: 34.5s\tremaining: 7m 5s\n",
      "2000:\tlearn: 18.6033901\ttest: 21.0901507\tbest: 21.0898946 (1998)\ttotal: 46s\tremaining: 6m 53s\n",
      "2500:\tlearn: 18.0001403\ttest: 20.9189709\tbest: 20.9179042 (2497)\ttotal: 57.3s\tremaining: 6m 40s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.83272521\n",
      "bestIteration = 2884\n",
      "\n",
      "Shrink model to first 2885 iterations.\n",
      "0:\tlearn: 93.6836120\ttest: 93.8048705\tbest: 93.8048705 (0)\ttotal: 22.1ms\tremaining: 7m 21s\n",
      "500:\tlearn: 21.6838026\ttest: 22.6620653\tbest: 22.6620385 (498)\ttotal: 12.6s\tremaining: 8m 8s\n",
      "1000:\tlearn: 20.3860842\ttest: 22.1147050\tbest: 22.1147050 (1000)\ttotal: 22.5s\tremaining: 7m 6s\n",
      "1500:\tlearn: 19.4365712\ttest: 21.7711770\tbest: 21.7711770 (1500)\ttotal: 32.2s\tremaining: 6m 36s\n",
      "2000:\tlearn: 18.6383077\ttest: 21.4666084\tbest: 21.4666084 (2000)\ttotal: 42.2s\tremaining: 6m 19s\n",
      "2500:\tlearn: 18.0325449\ttest: 21.2650450\tbest: 21.2611437 (2489)\ttotal: 53.3s\tremaining: 6m 12s\n",
      "3000:\tlearn: 17.5008394\ttest: 21.1326753\tbest: 21.1317714 (2997)\ttotal: 1m 4s\tremaining: 6m 2s\n",
      "3500:\tlearn: 17.0487450\ttest: 21.0214030\tbest: 21.0214030 (3500)\ttotal: 1m 16s\tremaining: 5m 58s\n",
      "4000:\tlearn: 16.6696125\ttest: 20.9375380\tbest: 20.9349086 (3927)\ttotal: 1m 26s\tremaining: 5m 44s\n",
      "4500:\tlearn: 16.3058013\ttest: 20.8892123\tbest: 20.8892123 (4500)\ttotal: 1m 36s\tremaining: 5m 31s\n",
      "5000:\tlearn: 15.9424676\ttest: 20.7979759\tbest: 20.7977227 (4999)\ttotal: 1m 48s\tremaining: 5m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20.76692964\n",
      "bestIteration = 5139\n",
      "\n",
      "Shrink model to first 5140 iterations.\n"
     ]
    }
   ],
   "source": [
    "preds_C = []\n",
    "for i in seeds:\n",
    "    X_C, Val_C = get_validation_data(cleaned_C_train,i)\n",
    "    model_c = get_regressor()\n",
    "    \n",
    "    X_pool = Pool(X_C, label=X_C.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_val = Pool(Val_C, label=Val_C.pop('pv_measurement'), cat_features=categorical_features)\n",
    "    X_pool_test = Pool(cleaned_C_test, cat_features=categorical_features)\n",
    "    \n",
    "    model_c.fit(X_pool,eval_set=X_pool_val)\n",
    "    \n",
    "    \n",
    "    \n",
    "    prediction_C = model_c.predict(X_pool_test)\n",
    "    preds_C.append(prediction_C)\n",
    "    \n",
    "prediction_C = np.mean(preds_C, axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save predictions to submit file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction_C))\n",
    "assert len(prediction_A) == 720 and len(prediction_B) == 720 and len(prediction_C) == 720\n",
    "from datetime import datetime\n",
    "\n",
    "t = []\n",
    "t.extend(prediction_A)\n",
    "t.extend(prediction_B)\n",
    "t.extend(prediction_C)\n",
    "\n",
    "\n",
    "t = [max(i,0) for i in t] # Remove any negative values\n",
    "\n",
    "df = pd.DataFrame({'id': range(720 * 3), 'prediction': [0] * (720 * 3)})\n",
    "df['prediction'] = t\n",
    "\n",
    "df.to_csv(f'submission_{str(datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\"))}_notebook_1.csv', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
